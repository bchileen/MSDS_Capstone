---
title: "Predictive Dredging Models for Upper Mississippi River and Illinois Waterway"
subtitle: "Capstone Project - Machine Learning for Shoaling Rate Forecasting"
author: "Barrie Chileen Martinez"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    code_folding: show
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 12,
  fig.height = 8
)
```

# Loading in Code and Packages

```{r load-packages}
# Core data manipulation and visualization
library(tidyverse)
library(lubridate)
library(knitr)
library(kableExtra)

# Machine learning frameworks
library(caret)
library(xgboost)

# Time series and deep learning
library(keras3)
library(tensorflow)
library(zoo)
library(forecast)

# Statistical analysis and visualization
library(corrplot)
library(ggfortify)
library(viridis)
library(patchwork)
library(gridExtra)
library(scales)

# Parallel processing
library(doParallel)
library(foreach)

```

# Create Output directories and configure parallel processing

```{r}
# Set random seed for reproducibility
set.seed(118)

# Set up parallel processing
n_cores <- max(1, detectCores() - 1)
cl <- makeCluster(n_cores)
registerDoParallel(cl)
n_cores

# Create output directories
output_dirs <- c(
"./Output",
"./Output/PCA",
"./Output/xGBoost",
"./Output/LSTM",
"./Output/Pool_Models",
"./Output/Comparisons",
"./Output/Maps"
)

for (dir in output_dirs) {
dir.create(dir, showWarnings = FALSE, recursive = TRUE)
}

```

# Load Raw Data

```{r}
# Load datasets
gage_data <- read_csv("UMR_IWW_1999_2024.csv", show_col_types = FALSE)
CSAT_data <- read_csv("CSAT_DATA_Combined.csv", show_col_types = FALSE)
gage_metadata <- read_csv("gage_metadata.csv", show_col_types = FALSE)
dredge_data <- read_csv("Dredge_Event_data.csv", show_col_types=FALSE)

# Data Overview

cat("Gage Data:\n")
cat("Dimensions:", nrow(gage_data), "rows x", ncol(gage_data), "columns\n")
cat("Date range:", as.character(min(dmy(gage_data$Date), na.rm = TRUE)), "to",
    as.character(max(dmy(gage_data$Date), na.rm = TRUE)),"\n\n")

cat("CSAT Data:\n")
cat("Dimensions:", nrow(CSAT_data), "rows x", ncol(CSAT_data), "columns\n")
cat("Shoaling rate range:", 
    round(min(CSAT_data$AnnualShoalingRate_ftperyr, na.rm = TRUE), 3), "to",
    round(max(CSAT_data$AnnualShoalingRate_ftperyr, na.rm = TRUE), 3), "ft/yr\n\n")

cat("Gage Metadata:\n")
cat("Total gages:", nrow(gage_metadata), "\n")
```

## Split Gages by River

```{r}
# Create gage lists for filtering
IWW_gages <- gage_metadata |>
filter(River == "IL") |>
pull(Gage_ID)

Miss_gages <- gage_metadata |>
filter(River == "UM") |>
pull(Gage_ID)

All_gages <- gage_metadata |>
pull(Gage_ID)

cat("Gage counts by river:\n")
cat("  Illinois Waterway:", length(IWW_gages), "gages\n")
cat("  Mississippi River:", length(Miss_gages), "gages\n")
cat("  Total:", length(All_gages), "gages\n")
```

## Clean Gage Data

```{r}
### All dates need to be made into a date object and lets create a variable for
### season of the year and factor it. The final step is to remove any rows with 
### an empty date since we wont be able to join them to the CSAT data
 gage_data_cleaned <- gage_data |>
    mutate(
      Date = dmy(Date),
      Year = year(Date),
      Month = month(Date),
      Day = yday(Date),
      WeekOfYear = week(Date),
      Season = case_when(
        Month %in% c(12, 1, 2) ~ "Winter",
        Month %in% c(3, 4, 5) ~ "Spring", 
        Month %in% c(6, 7, 8) ~ "Summer",
        Month %in% c(9, 10, 11) ~ "Fall"
      ),
      Season = factor(Season, levels = c("Winter", "Spring", "Summer", "Fall"))
    ) |>
    filter(!is.na(Date)) |>
    arrange(Date)

### Now lets take a look at NA counts 
na_counts <- colSums(is.na(gage_data_cleaned))
names<-names(gage_data_cleaned)
cat("Missing values before interpolation:", 
    sum(is.na(select(gage_data_cleaned, -Date, -Year, -Month, -Day, -WeekOfYear, -Season))), "\n")


### Thats not too bad, lets try interpolating some dates. Lets use a gap of 4 
### days which is reasonable for river gage forecasts
gage_cols <- setdiff(names(gage_data_cleaned), c("Date", "Year", "Month", "Day", "WeekOfYear", "Season"))

# Apply interpolation to each gage column
gage_data_interpolated <- gage_data_cleaned |>
mutate(across(
  all_of(gage_cols),
  ~ na.approx(.x, x = Date, maxgap = 4, na.rm = FALSE)
))

### Print the missing values pre and post interpolation
cat("Missing values after interpolation:", 
    sum(is.na(select(gage_data_interpolated, all_of(gage_cols)))), "\n")
```

## Clean CSAT Data

```{r}
### All dates need to be made into a date object and lets create a variable for
### season of the year and factor it. Add additional fields for days between 
### surveys as well as a reliability indicator. Filter empty shoaling rates and
### make sure that the shoaling rate is <30 and the days between are within 1 year
 CSAT_data_cleaned <- CSAT_data |>
    mutate(
      SurveyDateBefore = ymd(as.character(SurveyDateBefore)),
      SurveyDateAfter = ymd(as.character(SurveyDateAfter)),
      DaysBetween = as.numeric(SurveyDateAfter - SurveyDateBefore),
      rate_reliability = case_when(DaysBetween <= 30 ~ 1.0,
  DaysBetween <= 60 ~ 0.8,  # High quality
  DaysBetween <= 180 ~ 0.6,  # Medium quality  
  DaysBetween <= 240 ~ 0.4,  # Low quality
  TRUE ~ 0.2  # Very low quality
)
    ) |>
    filter(!is.na(AnnualShoalingRate_ftperyr), 
           !is.infinite(AnnualShoalingRate_ftperyr),
           abs(AnnualShoalingRate_ftperyr)<= 30, 
           DaysBetween <= 365)

```

## Join the Datasets

```{r join-data}
# Join CSAT with gage data on survey date
gage_CSAT_joined <- CSAT_data_cleaned |>
left_join(
  gage_data_interpolated,
  by = c("SurveyDateBefore" = "Date")
) 

# Check pool sample counts
pool_counts <- gage_CSAT_joined |>
group_by(pool) |>
summarise(count = n(), .groups = "drop") |>
arrange(desc(count))

cat("Pool sample counts:\n")
print(pool_counts)

# Filter out pools with insufficient data
pools_to_exclude <- c("AL", "LP", "BR", "CS", "24")
gage_CSAT_joined <- gage_CSAT_joined |>
filter(!pool %in% pools_to_exclude)

cat("\nAfter filtering pools:", nrow(gage_CSAT_joined), "observations\n")
cat("Date range:", as.character(min(gage_CSAT_joined$SurveyDateBefore)), "to",
    as.character(max(gage_CSAT_joined$SurveyDateBefore)), "\n")
```

### Create River-Specific Datasets

```{r river-datasets}
# Split data by river system
IWW_data <- gage_CSAT_joined |>
filter(river == "IL") |>
mutate(pool = as.factor(pool))

Miss_data <- gage_CSAT_joined |>
filter(river == "UM") |>
mutate(pool = as.factor(pool))

cat("Dataset sizes:\n")
cat("  Illinois Waterway:", nrow(IWW_data), "observations\n")
cat("  Mississippi River:", nrow(Miss_data), "observations\n")
cat("  Combined:", nrow(gage_CSAT_joined), "observations\n")
```

# Exploratory Data Analysis

## Distribution Plots

```{r distrib plots, fig.height=10}
### Lets make a series of plots to view the distribution of the data
target_plots <- list()

# Custom labels for rivers
custom_labels <- c(
      "IL" = "Illinois Waterway",
      "UM" = "Mississippi River"
    )

# 1. Distribution
target_plots$dist <- gage_CSAT_joined |>
  ggplot(aes(x =  AnnualShoalingRate_ftperyr)) +
  geom_histogram(bins = 50, fill = "steelblue", alpha = 0.7) +
  geom_vline(aes(xintercept = median( AnnualShoalingRate_ftperyr, na.rm = TRUE)), 
             color = "red", linetype = "dashed", size = 1) +
  labs(title = "Distribution of Annual Shoaling Rate(ft/yr)",
       x = "Annual Shoaling Rate(ft/yr)",
       y = "Frequency") +
  theme_minimal()

# Full time series 
target_plots$ts <- gage_CSAT_joined |>
  ggplot(aes(x = SurveyDateBefore, y = AnnualShoalingRate_ftperyr)) +
  geom_line(alpha = 0.6, color = "steelblue") +
  geom_smooth(method = "loess", span = 0.3, se = FALSE, color = "red", size = 1) +
  facet_wrap(~river, scales = "free_y", labeller = as_labeller(custom_labels)) +
  labs(title = "Shoaling Rate Time Series by River",
       x = "Date", y = "7-Day Average Shoaling Rate") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# 3. Seasonal patterns
target_plots$seasonal <- gage_CSAT_joined |>
  group_by(Month, river) |>
  summarise(avg_shoaling = mean(AnnualShoalingRate_ftperyr, na.rm = TRUE), .groups = "drop") |>
  ggplot(aes(x = Month, y = avg_shoaling, color = river)) +
    scale_color_manual(values = c("IL" = "orange", "UM" = "dodgerblue"),
    labels = c("IL" = "Illinois Waterway", "UM" = "Mississippi River"),
    name = "River")+
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  labs(title = "Seasonal Shoaling Patterns",
       x = "Month", y = "Average Shoaling Rate",
       color = "River") +
  theme_minimal()

target_plots$seasonal

ggsave("./Output/EDA/SeasonalRates.png", width = 8, height = 3)

# Display plots
grid.arrange(target_plots$dist, target_plots$seasonal, ncol = 1)
target_plots$ts

ggplot(gage_CSAT_joined,aes(x = SurveyDateBefore, y = AnnualShoalingRate_ftperyr, color = river))+
         geom_line()+ 
  scale_color_manual(values = c("IL" = "orange", "UM" = "dodgerblue"),
    labels = c("IL" = "Illinois Waterway", "UM" = "Mississippi River"),
    name = "River")+ 
  labs(x = "Survey Date", y = "Annual Shoaling Rate (ft/yr)", title = "Annual Shoaling Rates By Pool")+
  facet_wrap(~pool)

ggsave("./Output/EDA/Pool_Timeseries.png", width = 10, height = 8)
```

## Dredge Data Exploration (Need to establish shoaling threshold)

```{r}
dredge_clean <- dredge_data |>
  filter(EXECYEAR >= 1999) |>
  mutate(
    dredge_date = as.Date(mdy_hm(DATE_START)),
    river_code = case_when(
      RIVER == "Illinois_Waterway" ~ "IL",
      RIVER == "Mississippi_River" ~ "UM"),
    pool_clean = POOL) |>
  filter(!is.na(dredge_date))

CSAT_clean <- CSAT_data_cleaned |>
  mutate(
    SurveyDateBefore = ymd(as.character(SurveyDateBefore)),
    SurveyDateAfter = ymd(as.character(SurveyDateAfter)),
    river_code = river,
    pool_clean = pool
  )

# Match - dredge event occurred within 30 days AFTER survey ended
CSAT_pre_dredge <- CSAT_clean |>
  inner_join(
    dredge_clean |> 
      select(dredge_date, river_code, pool_clean, volume_dredged = VOLUMEDREDGED),
    by = c("river_code", "pool_clean"),
    relationship = "many-to-many") |>
  mutate(days_to_dredge = as.numeric(dredge_date - SurveyDateAfter)) |>
  filter(days_to_dredge >= 0, days_to_dredge <= 30) |>  # Within 30 days
  group_by(across(c(-dredge_date, -volume_dredged, -days_to_dredge))) |>
  slice_min(days_to_dredge, n = 1) |>  # Keep closest match
  ungroup()

comb_thresh = round(mean(CSAT_pre_dredge$AnnualShoalingRate_ftperyr),2)

cat("Matched CSAT records:", nrow(CSAT_pre_dredge), "\n\n")

# Quick histogram
hist(CSAT_pre_dredge$AnnualShoalingRate_ftperyr, 
     breaks = 50, 
     main = "Shoaling Rates Before Dredge Events",
     xlab = "Annual Shoaling Rate (ft/yr)",
     col = "steelblue")
abline(v = mean(CSAT_pre_dredge$AnnualShoalingRate_ftperyr, na.rm = TRUE), 
       col = "red", lwd = 2, lty = 2)

river_thresholds <- CSAT_pre_dredge |>
  group_by(river) |>
  summarise(
    n_events = n(),
    mean_rate = round(mean(AnnualShoalingRate_ftperyr, na.rm = TRUE), 2),
    median_rate = round(median(AnnualShoalingRate_ftperyr, na.rm = TRUE), 2),
    pct_positive = round(mean(AnnualShoalingRate_ftperyr > 0, na.rm = TRUE) * 100, 1)
  )
print(river_thresholds)

pool_thresholds <- CSAT_pre_dredge |>
  group_by(pool) |>
  summarise(
    n_events = n(),
    mean_rate = round(mean(AnnualShoalingRate_ftperyr, na.rm = TRUE), 2),
    median_rate = round(median(AnnualShoalingRate_ftperyr, na.rm = TRUE), 2),
    pct_positive = round(mean(AnnualShoalingRate_ftperyr > 0, na.rm = TRUE) * 100, 1)
  )
print(pool_thresholds)

reach_thresholds <-CSAT_pre_dredge |>
  group_by(pool, reach) |>
  summarise(
    n_events = n(),
    mean_rate = round(mean(AnnualShoalingRate_ftperyr, na.rm = TRUE), 2),
    median_rate = round(median(AnnualShoalingRate_ftperyr, na.rm = TRUE), 2),
    pct_positive = round(mean(AnnualShoalingRate_ftperyr > 0, na.rm = TRUE) * 100, 1)
  )
print(reach_thresholds)
```

## Correlation Matrix

```{r corrplot, fig.height=10}
### Select all numeric predictors, exclude annual shoaling rate since that's what
### were trying to model and use the cor function to make a correlation matrix
cor_matrix<-gage_CSAT_joined|>
  select(where(is.numeric),-AnnualShoalingRate_ftperyr)|>
  cor(use = "pairwise.complete.obs")
cor_matrix

### Select the highly correlated pairs and store in a dataframe
high_cor_pairs<- function(cor_mat, threshold = 0.7){
  cor_mat[lower.tri(cor_mat)] <- NA
  diag(cor_mat) <- NA

  high_cor <- which(abs(cor_mat) > threshold, arr.ind=TRUE)
  if (nrow(high_cor) > 0) {
    data.frame(
      var1 = rownames(cor_mat)[high_cor[,1]],
      var2 = rownames(cor_mat)[high_cor[,2]],
      correlation = cor_mat[high_cor]) |>
      arrange(desc(abs(correlation)))
} else {
  data.frame()
}
}

### Plot the corrplot 
library(corrplot)
corrplot(cor_matrix, tl.cex = 0.75, type = "upper", method = "color",
          order = "hclust", tl.col = "black")
```

## Create pool-level datasets

```{r}
### Pool statistics
pool_samples <- CSAT_data_cleaned |>
group_by(pool, river) |>
summarise(
  n_samples = n(),
  min_date = min(SurveyDateBefore),
  max_date = max(SurveyDateBefore),
  avg_shoaling = mean(AnnualShoalingRate_ftperyr, na.rm = TRUE),
  sd_shoaling = sd(AnnualShoalingRate_ftperyr, na.rm = TRUE),
  pct_positive = mean(AnnualShoalingRate_ftperyr > 0, na.rm = TRUE),
  .groups = "drop"
) |>
mutate(
  river_name = ifelse(river == "IL", "Illinois Waterway", "Mississippi River")
)

# Summarize gage information per pool
pool_gages <- gage_metadata |>
filter(!is.na(Pool)) |>
group_by(Pool, River) |>
summarise(
  n_gages_in_pool = n(),
  n_main_gages = sum(GageType == "Main"),
  n_trib_gages = sum(GageType == "Trib"),
  min_rm = min(RiverMile),
  max_rm = max(RiverMile),
  .groups = "drop"
)

# Join pool information
pool_info <- pool_samples |>
left_join(pool_gages, by = c("pool" = "Pool", "river" = "River"))|>
  mutate(center_rm = (min_rm + max_rm) / 2)  

cat("Pool Information Summary:\n")
print(pool_info |> select(pool, river_name, n_samples, n_gages_in_pool, pct_positive))

```

### Select gages upstream and within pools

```{r gage selection}
# Function to select gages relevant to a specific pool
select_pool_gages <- function(target_pool, target_river, metadata,
                             upstream_distance = 100,
                             include_tributaries = TRUE) {

# Get gages in the target pool
pool_gages_df <- metadata |>
  filter(Pool == target_pool, River == target_river)

if (nrow(pool_gages_df) == 0) return(NULL)

pool_max_rm <- max(pool_gages_df$RiverMile, na.rm = TRUE)
pool_min_rm <- min(pool_gages_df$RiverMile, na.rm = TRUE)

# Start with gages directly in the pool
selected <- pool_gages_df$Gage_ID

# Add upstream main channel gages
upstream_main <- metadata |>
  filter(
    River == target_river,
    GageType == "Main",
    RiverMile > pool_max_rm,
    RiverMile <= pool_max_rm + upstream_distance
  ) |>
  pull(Gage_ID)

selected <- unique(c(selected, upstream_main))

# Add tributary gages 
if (include_tributaries) {
  pool_tribs <- metadata |>
    filter(River == target_river, GageType == "Trib", Pool == target_pool) |>
    pull(Gage_ID)
  
  upstream_tribs <- metadata |>
    filter(
      River == target_river,
      GageType == "Trib",
      RiverMile > pool_max_rm,
      RiverMile <= pool_max_rm + upstream_distance
    ) |>
    pull(Gage_ID)
  
  selected <- unique(c(selected, pool_tribs, upstream_tribs))
}

return(selected)
}
```

### Assign gages to pools

```{r}
# Function to create complete mapping
create_pool_gage_mapping <- function(pool_info, metadata, upstream_distance = 100) {

  mapping <- list()
  
  for (i in 1:nrow(pool_info)) {
    pool <- pool_info$pool[i]
    river <- pool_info$river[i]
    key <- paste(river, pool, sep = "_") 
    
    gages <- select_pool_gages(
      target_pool = pool,
      target_river = river,
      metadata = metadata,
      upstream_distance = upstream_distance
    )
    
    mapping[[key]] <- list(
      pool = pool,
      river_code = river,
      river_filter = river,
      n_samples = pool_info$n_samples[i],
      selected_gages = gages,
      n_selected_gages = length(gages)
    )
  }
  
  return(mapping)
}
# Create mapping
pool_gage_mapping <- create_pool_gage_mapping(pool_info, gage_metadata)

# Display mapping summary
mapping_summary <- data.frame(
Key = names(pool_gage_mapping),
Pool = sapply(pool_gage_mapping, function(x) x$pool),
River = sapply(pool_gage_mapping, function(x) x$river_code),
N_Samples = sapply(pool_gage_mapping, function(x) x$n_samples),
N_Gages = sapply(pool_gage_mapping, function(x) x$n_selected_gages)
)


print(mapping_summary |> arrange(River, desc(N_Samples)))
```

## Principal Components Analysis

### Combined PCA

```{r Combined PCA}
colSums(is.na(gage_CSAT_joined))

 gage_survey_PCA <- gage_CSAT_joined |>
 select(where(is.numeric),
        -Year, -Month, -Day,-WeekOfYear, -SurveyDateBefore,-SurveyDateAfter,
        -rate_reliability,-reach, -NetVolumeChange_CY, -AnnualShoalingVolume_CYperyr, -AnnualShoalingRate_ftperyr, -SurveyOverlapArea_sqft, -SurveyOverlapPctReach)

# Remove rows with any missing values for PCA 
pca_data_complete <- gage_survey_PCA |>
  drop_na()

cat("Complete cases for PCA:", nrow(pca_data_complete), "out of", nrow(gage_CSAT_joined), "\n")
 
Comb_Viz <- gage_CSAT_joined |>
  dplyr::slice(as.numeric(rownames(pca_data_complete))) |>  
  select(SurveyDateBefore, Day, Month, WeekOfYear,
         river, pool, Season) |>
  mutate(
    season = factor(Season, levels = c("Winter", "Spring", "Summer", "Fall")),
    river_system = factor(river),
    pool_name = factor(pool),
    week_of_year = WeekOfYear)
  

Combined_PCA = prcomp(pca_data_complete, scale = T, center = T)

#Variance Explained
Combined_explained_variance <- summary(Combined_PCA)$importance[2, ] * 100
Combined_cumulative_variance <- summary(Combined_PCA)$importance[3, ] * 100
Combined_eigenvalues <- (Combined_PCA$sdev)^2
Combined_components_kaiser <- sum(Combined_eigenvalues > 1)

cat("\nCombined PCA Results:\n")
cat("  Variance explained (PC1-5):", round(Combined_explained_variance[1:5], 2), "%\n")
cat("  Cumulative variance (PC1-5):", round(Combined_cumulative_variance[1:5], 2), "%\n")
cat("  Components with eigenvalue > 1:", Combined_components_kaiser, "\n")

# Scree Plot
plot(Combined_PCA,  type="l", title = "Combined PCA Scree Plot")

# Biplot Function
plot_PCA_biplot <- function(River_df, River_Viz,RiverName) {
a<-autoplot(River_df,data = River_Viz, 
         color = 'season',loadings = TRUE,
             loadings.label = TRUE, # Show loading labels
             loadings.colour = "blue", # Color loading arrows
             loadings.label.colour = "darkblue")+
  ggtitle("Season")

b<-autoplot(River_df,data = River_Viz, 
         color = 'pool',loadings= TRUE,
             loadings.label = TRUE, # Show loading labels
             loadings.colour = "blue", # Color loading arrows
             loadings.label.colour = "darkblue")+
  labs(color = "Pool")+
  ggtitle(RiverName)+
    guides(color = guide_legend(ncol = 3))


c<-autoplot(River_df,data = River_Viz, 
         color = 'week_of_year',loadings = TRUE,
             loadings.label = TRUE, # Show loading labels
             loadings.colour = "blue", # Color loading arrows
             loadings.label.colour = "darkblue")+
        ggtitle("Week ")+
  labs(color = "Week of Year?")

library(patchwork)
combined <- a + b + c + plot_layout(ncol = 3) +
  plot_annotation(title = RiverName)

return(combined)
}

Combined_Biplots <- plot_PCA_biplot(Combined_PCA,Comb_Viz, "Combined Rivers")

Combined_Biplots

ggsave("./Output/PCA/Combined_PCA_Biplots.png", width = 18, height = 9)
```

## River-Specific PCA

```{r, fig.height=8}
IWW_complete<- gage_CSAT_joined |>
filter(river == "IL")|>
  select(any_of(IWW_gages), SurveyDateBefore, Season, Day, Month, WeekOfYear,
         river, pool) |>
  drop_na(any_of(IWW_gages)) 


IWW_PCA_data <- IWW_complete|>
select(any_of(IWW_gages)) 

IWW_PCA <- prcomp(IWW_pca_data, scale = TRUE, center = TRUE)
IWW_explained_variance <- summary(IWW_PCA)$importance[2, ] * 100
IWW_cumulative_variance <- summary(IWW_PCA)$importance[3, ] * 100

# Mississippi PCA
Miss_complete <- gage_CSAT_joined |>
filter(river == "UM") |>
  select(any_of(Miss_gages), SurveyDateBefore, Season, Day, Month, WeekOfYear,
         river, pool) |>
    drop_na(any_of(Miss_gages)) 

Miss_pca_data <- Miss_complete|>
  select(any_of(Miss_gages))

Miss_PCA <- prcomp(Miss_pca_data, scale = TRUE, center = TRUE)
Miss_explained_variance <- summary(Miss_PCA)$importance[2, ] * 100
Miss_cumulative_variance <- summary(Miss_PCA)$importance[3, ] * 100

# Biplots of Miss and IL
IWW_Viz <-IWW_complete |>
  select(SurveyDateBefore, Season, Day, Month, WeekOfYear, river, pool) |>
  mutate(
    season = factor(Season, levels = c("Winter", "Spring", "Summer", "Fall")),
    river_system = factor(river),
    pool_name = factor(pool),
    week_of_year = WeekOfYear)

Miss_Viz <- Miss_complete |>
  select(SurveyDateBefore, Season, Day, Month, WeekOfYear, river, pool) |>
  mutate(
    season = factor(Season, levels = c("Winter", "Spring", "Summer", "Fall")),
    river_system = factor(river),
    pool_name = factor(pool),
    week_of_year = WeekOfYear)


IWW_Biplots <- plot_PCA_biplot(IWW_PCA,IWW_Viz, "Illinois Waterway")
IWW_Biplots[[2]]
ggsave("./Output/PCA/IWW_Season_PCA.png", width = 12, height = 6)
IWW_Biplots
ggsave("./Output/PCA/IWW_PCA_Biplots.png", width = 18, height = 9)

Miss_Biplots <- plot_PCA_biplot(Miss_PCA,Miss_Viz, "Mississippi River")
Miss_Biplots
ggsave("./Output/PCA/Miss_PCA_Biplots.png", width = 18, height = 9)
Miss_Biplots[[2]]
ggsave("./Output/PCA/Miss_Season_PCA.png", width = 12, height = 6)

# Comparison table
pca_comparison <- data.frame(
Analysis = c("IWW Only", "Mississippi Only", "Combined"),
Observations = c(nrow(IWW_pca_data), nrow(Miss_pca_data), nrow(pca_data_complete)),
Variables = c(ncol(IWW_pca_data), ncol(Miss_pca_data), ncol(pca_data_complete)),
PC1_Variance = c(round(IWW_explained_variance[1], 2),
                 round(Miss_explained_variance[1], 2),
                 round(Combined_explained_variance[1], 2)),
PC2_Variance = c(round(IWW_explained_variance[2], 2),
                 round(Miss_explained_variance[2], 2),
                 round(Combined_explained_variance[2], 2)),
PC1_PC2_Combined = c(round(IWW_explained_variance[1] + IWW_explained_variance[2], 2),
                     round(Miss_explained_variance[1] + Miss_explained_variance[2], 2),
                     round(Combined_explained_variance[1] + Combined_explained_variance[2], 2))
)

cat("\nPCA Comparison Summary:\n")
print(pca_comparison)

# Variance comparison plot
variance_data <- data.frame(
Component = rep(1:10, 3),
Variance = c(IWW_explained_variance[1:10],
             Miss_explained_variance[1:10],
             Combined_explained_variance[1:10]),
Cumulative = c(IWW_cumulative_variance[1:10],
               Miss_cumulative_variance[1:10],
               Combined_cumulative_variance[1:10]),
Analysis = rep(c("IWW Only", "Mississippi Only", "Combined"), each = 10)
)

p_var <- ggplot(variance_data, aes(x = Component, y = Variance, color = Analysis)) +
geom_line(linewidth = 1.2) +
geom_point(size = 3) +
scale_color_viridis_d() +
labs(title = "Variance Explained by Principal Components",
    x = "Principal Component", y = "Variance Explained (%)") +
theme_minimal()

p_cum <- ggplot(variance_data, aes(x = Component, y = Cumulative, color = Analysis)) +
geom_line(linewidth = 1.2) +
geom_point(size = 3) +
geom_hline(yintercept = c(80, 85, 90), linetype = "dashed", alpha = 0.5) +
scale_color_viridis_d() +
labs(title = "Cumulative Variance Explained",
    x = "Principal Component", y = "Cumulative Variance (%)") +
theme_minimal()

p_var / p_cum

ggsave("./Output/PCA/Variance_Comparison.png", width = 12, height = 10)

Miss_Iww_Biplot <-Miss_Biplots[[2]] + IWW_Biplots[[2]]+plot_layout(ncol = 2) +  plot_annotation(title = "PCA of Illinois Waterway and Mississippi River")
ggsave("./Output/PCA/Miss_IWW_Biplot.png", width =10, height = 4)
```

# Utility Functions

```{r temporal-splits-function}
create_temporal_splits <- function(data, train_prop = 0.70, val_prop = 0.15) {

# Ensure data is sorted by date
data <- data |> arrange(SurveyDateBefore)

n <- nrow(data)
train_end <- floor(n * train_prop)
val_end <- floor(n * (train_prop + val_prop))

splits <- list(
  train_idx = 1:train_end,
  val_idx = (train_end + 1):val_end,
  test_idx = (val_end + 1):n,
  train_dates = data$SurveyDateBefore[1:train_end],
  val_dates = data$SurveyDateBefore[(train_end + 1):val_end],
  test_dates = data$SurveyDateBefore[(val_end + 1):n]
)

cat(sprintf("Temporal splits:\n"))
cat(sprintf("  Training: %d samples (%.1f%%) - %s to %s\n",
            length(splits$train_idx), train_prop * 100,
            min(splits$train_dates), max(splits$train_dates)))
cat(sprintf("  Validation: %d samples (%.1f%%) - %s to %s\n",
            length(splits$val_idx), val_prop * 100,
            min(splits$val_dates), max(splits$val_dates)))
cat(sprintf("  Test: %d samples (%.1f%%) - %s to %s\n",
            length(splits$test_idx), (1 - train_prop - val_prop) * 100,
            min(splits$test_dates), max(splits$test_dates)))

return(splits)
}

# Create splits for each dataset
IWW_splits <- create_temporal_splits(IWW_data)
Miss_splits <- create_temporal_splits(Miss_data)
Combined_splits <- create_temporal_splits(gage_CSAT_joined)
```

## Binary Classification Function (Convert shoaling rates to dredge yes/no class)

```{r}
print(river_thresholds)
print(pool_thresholds)

IWW_thresh = river_thresholds |>
  filter(river == "IL")|>
  pull(mean_rate)
Miss_thresh = river_thresholds |>
  filter(river == "UM")|>
  pull(mean_rate)

calculate_classification_metrics <- function(actual, predicted, threshold) {

# Convert to binary
actual_bin <- ifelse(actual > threshold, "YES", "NO")
pred_bin <- ifelse(predicted > threshold, "YES", "NO")

# Confusion matrix components
TP <- sum(actual_bin == "YES" & pred_bin == "YES")
FP <- sum(actual_bin == "NO" & pred_bin == "YES")
FN <- sum(actual_bin == "YES" & pred_bin == "NO")
TN <- sum(actual_bin == "NO" & pred_bin == "NO")

# Metrics
accuracy <- (TP + TN) / (TP + FP + FN + TN)
precision <- ifelse((TP + FP) > 0, TP / (TP + FP), NA)
recall <- ifelse((TP + FN) > 0, TP / (TP + FN), NA)
f1 <- ifelse(!is.na(precision) & !is.na(recall) & (precision + recall) > 0,
             2 * precision * recall / (precision + recall), NA)

list(
  accuracy = accuracy,
  precision = precision,
  recall = recall,
  f1 = f1,
  confusion = table(Actual = actual_bin, Predicted = pred_bin)
)
}
```

# Baseline Models

```{r baseline-models}
create_baselines <- function(data, splits, dataset_name) {

train_data <- data[splits$train_idx, ]
test_data <- data[splits$test_idx, ]

# Persistence baseline (naive forecast)
persistence_pred <- c(
  tail(train_data$AnnualShoalingRate_ftperyr, 1),
  test_data$AnnualShoalingRate_ftperyr[-nrow(test_data)]
)
persistence_rmse <- sqrt(mean((persistence_pred - test_data$AnnualShoalingRate_ftperyr)^2))
persistence_mae <- mean(abs(persistence_pred - test_data$AnnualShoalingRate_ftperyr))

# Mean baseline
mean_pred <- rep(mean(train_data$AnnualShoalingRate_ftperyr, na.rm = TRUE), nrow(test_data))
mean_rmse <- sqrt(mean((mean_pred - test_data$AnnualShoalingRate_ftperyr)^2))
mean_mae <- mean(abs(mean_pred - test_data$AnnualShoalingRate_ftperyr))

# ARIMA baseline
train_ts <- ts(train_data$AnnualShoalingRate_ftperyr, frequency = 12)
arima_model <- auto.arima(train_ts, seasonal = TRUE, stepwise = TRUE,
                          approximation = FALSE, trace = FALSE)
arima_forecast <- forecast(arima_model, h = nrow(test_data))
arima_pred <- as.numeric(arima_forecast$mean)
arima_rmse <- sqrt(mean((arima_pred - test_data$AnnualShoalingRate_ftperyr)^2))
arima_mae <- mean(abs(arima_pred - test_data$AnnualShoalingRate_ftperyr))

results <- data.frame(
  Model = c("Persistence", "Mean", "ARIMA"),
  Test_RMSE = c(persistence_rmse, mean_rmse, arima_rmse),
  Test_MAE = c(persistence_mae, mean_mae, arima_mae),
  Dataset = dataset_name
) |>
arrange(Test_RMSE)

cat("\nBaseline Performance:\n")
print(results)

return(list(
  results = results,
  arima_model = arima_model,
  predictions = data.frame(
    actual = test_data$AnnualShoalingRate_ftperyr,
    persistence = persistence_pred,
    mean = mean_pred,
    arima = arima_pred,
    date = test_data$SurveyDateBefore
  )
))
}

# Create baselines
IWW_baselines <- create_baselines(IWW_data, IWW_splits, "Illinois Waterway")
Miss_baselines <- create_baselines(Miss_data, Miss_splits, "Mississippi River")
Combined_baselines <- create_baselines(gage_CSAT_joined |> mutate(pool = as.factor(pool)), Combined_splits, "Combined")
```

# xGBoost

## River Level xGBoost

### Model and Tuning Grid Set Up

```{r}
train_xgboost_temporal <- function(data, splits, gages_to_use, dataset_name, threshold) {

cat(sprintf("\n Training xGBoost: %s \n", dataset_name))

# Prepare features
xgb_features <- data |>
  select(AnnualShoalingRate_ftperyr, WeekOfYear, pool, any_of(gages_to_use)) |>
  drop_na()

n_samples <- nrow(xgb_features)
n_folds <- 5

# Create expanding window temporal folds
temporal_indices <- lapply(1:n_folds, function(i) {
  test_start <- floor(n_samples * i / (n_folds + 1))
  test_end <- floor(n_samples * (i + 1) / (n_folds + 1))
  list(train = 1:(test_start - 1), test = test_start:test_end)
})

temporal_indices <- temporal_indices[sapply(temporal_indices, function(x) length(x$train) > 50)]

# Training control
ctrl <- trainControl(
  method = "cv",
  number = length(temporal_indices),
  index = lapply(temporal_indices, `[[`, "train"),
  indexOut = lapply(temporal_indices, `[[`, "test"),
  verboseIter = FALSE,
  allowParallel = TRUE,
  savePredictions = "final"
)

# Tune grid
  tune_grid <- expand.grid(
    nrounds = c(100, 200),
    max_depth = c(4, 5),
    eta = c(0.05,0.1),
    gamma = c(0, 0.1),
    colsample_bytree = c(0.6, 0.8),
    min_child_weight = c(1, 3),
    subsample = c(0.8, 1.0)
  )
  11

cat(sprintf("Training with %d temporal CV folds...\n", length(temporal_indices)))

start_time <- Sys.time()
xgb_model <- caret::train(
  AnnualShoalingRate_ftperyr ~ .,
  data = xgb_features,
  method = "xgbTree",
  tuneGrid = tune_grid,
  trControl = ctrl,
  metric = "RMSE",
  verbose = FALSE
)
training_time <- difftime(Sys.time(), start_time, units = "mins")

cat(sprintf("Training time: %.2f minutes\n", as.numeric(training_time)))
cat(sprintf("Best CV RMSE: %.4f\n", min(xgb_model$results$RMSE)))
cat(sprintf("Best params: nrounds=%d, max_depth=%d, eta=%.3f\n",
            xgb_model$bestTune$nrounds,
            xgb_model$bestTune$max_depth,
            xgb_model$bestTune$eta))

# Test set evaluation
test_data <- data[splits$test_idx, ] |>
  select(AnnualShoalingRate_ftperyr, WeekOfYear, pool,
         any_of(gages_to_use), SurveyDateBefore) |>
  drop_na()

test_pred <- predict(xgb_model, newdata = test_data)
test_rmse <- sqrt(mean((test_pred - test_data$AnnualShoalingRate_ftperyr)^2))
test_mae <- mean(abs(test_pred - test_data$AnnualShoalingRate_ftperyr))
test_r2 <- cor(test_pred, test_data$AnnualShoalingRate_ftperyr)^2

# Classification metrics
class_metrics <- calculate_classification_metrics(
  test_data$AnnualShoalingRate_ftperyr, test_pred, threshold)

cat(sprintf("Test RMSE: %.4f, MAE: %.4f, RÂ²: %.4f\n", test_rmse, test_mae, test_r2))
cat(sprintf("Classification Accuracy: %.3f, F1: %.3f\n",
            class_metrics$accuracy, class_metrics$f1))

return(list(
  model = xgb_model,
  metrics = data.frame(
    Dataset = dataset_name,
    Model = "xGBoost",
    CV_RMSE = min(xgb_model$results$RMSE),
    Test_RMSE = test_rmse,
    Test_MAE = test_mae,
    Test_R2 = test_r2,
    Accuracy = class_metrics$accuracy,
    Precision = class_metrics$precision,
    Recall = class_metrics$recall,
    F1_Score = class_metrics$f1
  ),
  predictions = data.frame(
    actual = test_data$AnnualShoalingRate_ftperyr,
    predicted = test_pred,
    date = test_data$SurveyDateBefore
  ),
  confusion = class_metrics$confusion
))
}

```

### Train the models

```{r train-xgboost-river}
# Train river-level models
IWW_xgb <- train_xgboost_temporal(IWW_data, IWW_splits, IWW_gages, "Illinois Waterway", IWW_thresh)
Miss_xgb <- train_xgboost_temporal(Miss_data, Miss_splits, Miss_gages, "Mississippi River",Miss_thresh)
Combined_xgb <- train_xgboost_temporal(gage_CSAT_joined, Combined_splits, All_gages, "Combined", comb_thresh)
```

### Variable Importance

```{r}
# Extract and plot importance
iww_imp <- xgb.importance(model = IWW_xgb$model$finalModel)
miss_imp <- xgb.importance(model = Miss_xgb$model$finalModel)
combined_imp <- xgb.importance(model = Combined_xgb$model$finalModel)

cat("\nTop 10 Features - Illinois Waterway:\n")
print(head(iww_imp, 10))

cat("\nTop 10 Features - Mississippi River:\n")
print(head(miss_imp, 10))

# Save importance plots
png("./Output/xGBoost/IWW_Importance.png", width = 12, height = 8, units = "in", res = 300)
xgb.plot.importance(iww_imp[1:10, ], main = "Top 10 Features - Illinois Waterway")
dev.off()

png("./Output/xGBoost/Miss_Importance.png", width = 12, height = 8, units = "in", res = 300)
xgb.plot.importance(miss_imp[1:10, ], main = "Top 10 Features - Mississippi River")
dev.off()

png("./Output/xGBoost/Combined_Importance.png", width = 12, height = 8, units = "in", res = 300)
xgb.plot.importance(combined_imp[1:10, ], main = "Top 10 Features - Combined")
dev.off()

cat("\nImportance plots saved to ./Output/xGBoost/\n")
```

## Pool Level xGBoost

```{r}
train_pool_xgboost <- function(data, pool_name, river_code,
                              pool_gage_mapping, threshold, min_samples = 40) {

  key <- paste(river_code, pool_name, sep = "_")
  
  if (!key %in% names(pool_gage_mapping)) {
    return(list(pool = pool_name, river = river_code, status = "no_mapping", metrics = NULL))
  }
  
  pool_map <- pool_gage_mapping[[key]]
  river_filter <- pool_map$river_filter  # Now this exists
  selected_gages <- pool_map$selected_gages
  
  # Filter data for this pool
  pool_data <- data |>
    filter(pool == pool_name, river == river_filter) |>
    arrange(SurveyDateBefore)

if (nrow(pool_data) < min_samples) {
  return(list(pool = pool_name, river = river_code, status = "insufficient_samples",
              n = nrow(pool_data), metrics = NULL))
}

available_gages <- intersect(selected_gages, names(pool_data))

if (length(available_gages) < 2) {
  return(list(pool = pool_name, river = river_code, status = "insufficient_gages",
              n_gages = length(available_gages), metrics = NULL))
}

cat(sprintf("\n--- Pool %s (%s): %d samples, %d gages ---\n",
            pool_name, river_code, nrow(pool_data), length(available_gages)))

# Prepare features
features <- pool_data |>
  select(AnnualShoalingRate_ftperyr, WeekOfYear, DaysBetween, all_of(available_gages)) |>
  drop_na()

if (nrow(features) < 30) {
  return(list(pool = pool_name, river = river_code, status = "insufficient_complete",
              n_complete = nrow(features), metrics = NULL))
}

# Temporal split
n <- nrow(features)
train_end <- floor(n * 0.7)
test_start <- floor(n * 0.85) + 1

train_data <- features[1:train_end, ]
test_data <- features[test_start:n, ]

if (nrow(test_data) < 5) {
  return(list(pool = pool_name, river = river_code, status = "insufficient_test", metrics = NULL))
}

# Training
ctrl <- trainControl(method = "cv", number = 5, verboseIter = FALSE, allowParallel = TRUE)

tune_grid <- expand.grid(
  nrounds = c(50, 100, 150),
  max_depth = c(3, 4, 5, 6),
  eta = c(0.05, 0.1, 0.2),
  gamma = c(0, 0.1),
  colsample_bytree = c(0.7, 0.9),
  min_child_weight = c(1, 3),
  subsample = 0.8
)

model <- tryCatch({
  caret::train(
    AnnualShoalingRate_ftperyr ~ .,
    data = train_data,
    method = "xgbTree",
    tuneGrid = tune_grid,
    trControl = ctrl,
    metric = "RMSE",
    verbose = FALSE
  )
}, error = function(e) {
  cat(sprintf("  Training error: %s\n", e$message))
  return(NULL)
})

if (is.null(model)) {
  return(list(pool = pool_name, river = river_code, status = "training_failed", metrics = NULL))
}

# Evaluate
pred <- predict(model, test_data)
actual <- test_data$AnnualShoalingRate_ftperyr

rmse <- sqrt(mean((pred - actual)^2))
mae <- mean(abs(pred - actual))
r2 <- cor(pred, actual)^2

class_metrics <- calculate_classification_metrics(actual, pred, threshold)

cat(sprintf("  RMSE=%.3f, Accuracy=%.1f%%, F1=%.3f\n",
            rmse, class_metrics$accuracy * 100, class_metrics$f1))

return(list(
  pool = pool_name,
  river = river_code,
  status = "success",
  model = model,
  n_samples = nrow(pool_data),
  n_gages = length(available_gages),
  gages_used = available_gages,
  metrics = data.frame(
    Pool = pool_name,
    River = river_code,
    Model = "xGBoost",
    N_Samples = nrow(pool_data),
    N_Gages = length(available_gages),
    Test_RMSE = rmse,
    Test_MAE = mae,
    Test_R2 = r2,
    Accuracy = class_metrics$accuracy,
    Precision = class_metrics$precision,
    Recall = class_metrics$recall,
    F1_Score = class_metrics$f1
  ),
  predictions = data.frame(actual = actual, predicted = pred),
  confusion = class_metrics$confusion
))
}
```

### Run xGBoost at Pool Level

```{r}
viable_pools <- pool_info |>
  filter(n_samples >= 40) |>
  arrange(river, desc(n_samples))

cat(sprintf("Training pool-level xGBoost for %d viable pools\n", nrow(viable_pools)))

# Train models for each pool
pool_xgb_results <- list()

for (i in 1:nrow(viable_pools)) {
  pool_name <- viable_pools$pool[i]
  river_code <- viable_pools$river[i]  # This is "IL" or "UM"
  
  # Handle case where pool might not have threshold data
 pool_threshold <- pool_thresholds |>
    filter(pool == pool_name) |>
    pull(mean_rate)
  
  # Use river threshold as fallback if pool threshold missing
  if (length(pool_threshold) == 0) {
    pool_threshold <- river_thresholds |>
      filter(river == river_code) |>
      pull(mean_rate)
  }
  
  # Skip if still no threshold
 if (length(pool_threshold) == 0) {
    cat(sprintf("Skipping pool %s - no threshold available\n", pool_name))
    next
  }
  
  result <- train_pool_xgboost(
    data = gage_CSAT_joined,
    pool_name = pool_name,
    river_code = river_code,
    pool_gage_mapping = pool_gage_mapping,
    threshold = pool_threshold,
    min_samples = 40
  )
  
  key <- paste(river_code, pool_name, sep = "_")
  pool_xgb_results[[key]] <- result
}

# Compile results
pool_xgb_metrics <- do.call(rbind, lapply(pool_xgb_results, function(x) {
  if (!is.null(x$metrics)) x$metrics else NULL
}))

if (!is.null(pool_xgb_metrics)) {
  print(pool_xgb_metrics |> arrange(Test_RMSE))
}
```


# LSTM
LSTM Model developed using Claude AI on 11/01/2025. AI was used to build out the data preparation handling and workflow and to build model architecture to correctly handle temporal splits. Other reference materials include [R Bloggers Forecasting Sunspots](https://www.r-bloggers.com/2018/04/time-series-deep-learning-forecasting-sunspots-with-keras-stateful-lstm-in-r/)  and [Time Series Forecasting with RNN](https://blogs.rstudio.com/ai/posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks/){.uri} and [LSTM Time Series Prediction in R](http://datasideoflife.com/?p=1171)

## LSTM Data Preparation
## LSTM Data Preparation Function

```{r lstm-data-prep-function}
#' Prepare data for LSTM with proper normalization and sequence creation
#' 
#' Key fixes for flat predictions:
#' 1. Proper min-max scaling of target variable
#' 2. Correct temporal ordering
#' 3. No data leakage between train/val/test
#' 4. Proper 3D tensor creation for Keras

prepare_lstm_data_fixed <- function(data, 
                                    gages_to_use,
                                    sequence_length = 30,
                                    forecast_horizon = 40,
                                    train_prop = 0.70,
                                    val_prop = 0.15,
                                    dataset_name = "Dataset") {
  
  cat(sprintf("\n=== Preparing LSTM Data: %s ===\n", dataset_name))
  
 # Step 1: Sort by date and select features
  data <- data |>
    arrange(SurveyDateBefore) |>
    filter(!is.na(AnnualShoalingRate_ftperyr))
  
  # Identify available gages
  available_gages <- intersect(gages_to_use, names(data))
  
  if (length(available_gages) < 2) {
    cat("  ERROR: Insufficient gage columns available\n")
    return(NULL)
  }
  
  # Step 2: Select and prepare features
  feature_cols <- c("AnnualShoalingRate_ftperyr", "WeekOfYear", "DaysBetween", available_gages)
  feature_cols <- intersect(feature_cols, names(data))
  
  # Create feature matrix with complete cases only
  feature_data <- data |>
    select(all_of(feature_cols), SurveyDateBefore) |>
    drop_na()
  
  n_samples <- nrow(feature_data)
  min_required <- sequence_length + forecast_horizon + 50
  
  if (n_samples < min_required) {
    cat(sprintf("  ERROR: Insufficient samples (%d < %d required)\n", n_samples, min_required))
    return(NULL)
  }
  
  cat(sprintf("  Samples: %d, Features: %d, Gages: %d\n", 
              n_samples, length(feature_cols) - 1, length(available_gages)))
  
  # Step 3: Extract target and features
  target <- feature_data$AnnualShoalingRate_ftperyr
  dates <- feature_data$SurveyDateBefore
  
  features <- feature_data |>
    select(-SurveyDateBefore) |>
    as.matrix()
  
  # Step 4: CRITICAL - Proper normalization (key fix for flat predictions)
  n <- nrow(features)
  train_end <- floor(n * train_prop)
  val_end <- floor(n * (train_prop + val_prop))
  
  # Calculate scaling parameters from training data only (prevents data leakage)
  train_features <- features[1:train_end, ]
  
  # Feature scaling parameters
  feature_means <- colMeans(train_features, na.rm = TRUE)
  feature_sds <- apply(train_features, 2, sd, na.rm = TRUE)
  feature_sds[feature_sds == 0] <- 1  # Prevent division by zero
  
  # Target scaling parameters (very important for LSTM)
  target_mean <- mean(target[1:train_end], na.rm = TRUE)
  target_sd <- sd(target[1:train_end], na.rm = TRUE)
  if (target_sd == 0) target_sd <- 1
  
  # Apply normalization to ALL data using TRAINING parameters
  features_scaled <- scale(features, center = feature_means, scale = feature_sds)
  target_scaled <- (target - target_mean) / target_sd
  
  cat(sprintf("  Target mean: %.3f, sd: %.3f\n", target_mean, target_sd))
  cat(sprintf("  Scaled target range: [%.3f, %.3f]\n", 
              min(target_scaled), max(target_scaled)))
  
  # Step 5: Create sequences for LSTM
  create_sequences <- function(features, target, seq_len, horizon) {
    n <- nrow(features)
    n_sequences <- n - seq_len - horizon + 1
    
    if (n_sequences <= 0) {
      return(list(X = NULL, y = NULL, dates = NULL))
    }
    
    n_features <- ncol(features)
    
    # Initialize arrays
    X <- array(0, dim = c(n_sequences, seq_len, n_features))
    y <- matrix(0, nrow = n_sequences, ncol = horizon)
    seq_dates <- vector("list", n_sequences)
    
    for (i in 1:n_sequences) {
      X[i, , ] <- features[i:(i + seq_len - 1), ]
      y[i, ] <- target[(i + seq_len):(i + seq_len + horizon - 1)]
      seq_dates[[i]] <- dates[i + seq_len]
    }
    
    return(list(X = X, y = y, dates = unlist(seq_dates)))
  }
  
  sequences <- create_sequences(features_scaled, target_scaled, 
                                sequence_length, forecast_horizon)
  
  if (is.null(sequences$X)) {
    cat("  ERROR: Failed to create sequences\n")
    return(NULL)
  }
  
  n_sequences <- dim(sequences$X)[1]
  cat(sprintf("  Created %d sequences\n", n_sequences))
  
  # Step 6: Temporal split (no shuffling - maintain time order)
  train_seq_end <- floor(n_sequences * train_prop)
  val_seq_end <- floor(n_sequences * (train_prop + val_prop))
  
  X_train <- sequences$X[1:train_seq_end, , , drop = FALSE]
  y_train <- sequences$y[1:train_seq_end, , drop = FALSE]
  dates_train <- sequences$dates[1:train_seq_end]
  
  X_val <- sequences$X[(train_seq_end + 1):val_seq_end, , , drop = FALSE]
  y_val <- sequences$y[(train_seq_end + 1):val_seq_end, , drop = FALSE]
  dates_val <- sequences$dates[(train_seq_end + 1):val_seq_end]
  
  X_test <- sequences$X[(val_seq_end + 1):n_sequences, , , drop = FALSE]
  y_test <- sequences$y[(val_seq_end + 1):n_sequences, , drop = FALSE]
  dates_test <- sequences$dates[(val_seq_end + 1):n_sequences]
  
  cat(sprintf("  Train: %d, Val: %d, Test: %d sequences\n",
              nrow(X_train), nrow(X_val), nrow(X_test)))
  
  return(list(
    X_train = X_train, y_train = y_train,
    X_val = X_val, y_val = y_val,
    X_test = X_test, y_test = y_test,
    dates_train = dates_train, dates_val = dates_val, dates_test = dates_test,
    target_mean = target_mean, target_sd = target_sd,
    feature_means = feature_means, feature_sds = feature_sds,
    sequence_length = sequence_length, forecast_horizon = forecast_horizon,
    n_features = ncol(features), n_train = nrow(X_train),
    n_val = nrow(X_val), n_test = nrow(X_test),
    feature_names = colnames(features), dataset_name = dataset_name
  ))
}
```

## LSTM Model Architecture Function

```{r lstm-model-architecture}
#' Build LSTM model with architecture designed to prevent flat predictions
#' 
#' Key architectural fixes:
#' 1. Multiple LSTM layers with proper hidden sizes
#' 2. Batch normalization for training stability
#' 3. Dropout for regularization
#' 4. Huber loss (more robust than MSE for outliers)

build_lstm_model <- function(sequence_length,
                             n_features,
                             forecast_horizon,
                             lstm_units = c(128, 64, 32),
                             dropout_rate = 0.2,
                             learning_rate = 0.001) {
  
  cat(sprintf("\nBuilding LSTM: input=(%d, %d), output=%d\n",
              sequence_length, n_features, forecast_horizon))
  
  keras3::clear_session()
  
  inputs <- layer_input(shape = c(sequence_length, n_features))
  
  # First LSTM layer
  x <- inputs |>
    layer_lstm(units = lstm_units[1], return_sequences = TRUE,
               kernel_regularizer = regularizer_l2(0.001),
               recurrent_regularizer = regularizer_l2(0.001)) |>
    layer_batch_normalization() |>
    layer_dropout(rate = dropout_rate)
  
  # Second LSTM layer
  if (length(lstm_units) >= 2) {
    x <- x |>
      layer_lstm(units = lstm_units[2], return_sequences = TRUE,
                 kernel_regularizer = regularizer_l2(0.001)) |>
      layer_batch_normalization() |>
      layer_dropout(rate = dropout_rate)
  }
  
  # Third LSTM layer (final)
  if (length(lstm_units) >= 3) {
    x <- x |>
      layer_lstm(units = lstm_units[3], return_sequences = FALSE,
                 kernel_regularizer = regularizer_l2(0.001)) |>
      layer_batch_normalization() |>
      layer_dropout(rate = dropout_rate / 2)
  } else {
    x <- x |>
      layer_lstm(units = lstm_units[length(lstm_units)], return_sequences = FALSE)
  }
  
  # Dense layers
  x <- x |>
    layer_dense(units = 64, activation = "relu") |>
    layer_dropout(rate = dropout_rate / 2) |>
    layer_dense(units = 32, activation = "relu")
  
  # Output layer
  outputs <- x |>
    layer_dense(units = forecast_horizon, activation = "linear")
  
  model <- keras_model(inputs = inputs, outputs = outputs)
  
  model |> compile(
    optimizer = optimizer_adam(learning_rate = learning_rate),
    loss = loss_huber(),
    metrics = list(metric_mean_absolute_error(), metric_root_mean_squared_error())
  )
  
  return(model)
}
```

## Multi-Lookback Window Testing Function

```{r lstm-lookback-testing}
#' Test multiple lookback windows to find optimal sequence length

test_lookback_windows <- function(data,
                                   gages_to_use,
                                   lookback_windows = c(7, 14, 30, 60),
                                   forecast_horizon = 40,
                                   threshold,
                                   epochs = 75,
                                   patience = 15,
                                   dataset_name = "Dataset") {
  
  cat(sprintf("\n%s\n", strrep("=", 70)))
  cat(sprintf("TESTING LOOKBACK WINDOWS: %s\n", dataset_name))
  cat(sprintf("Windows to test: %s\n", paste(lookback_windows, collapse = ", ")))
  cat(sprintf("%s\n\n", strrep("=", 70)))
  
  results <- list()
  
  for (lookback in lookback_windows) {
    cat(sprintf("\n--- Testing lookback = %d days ---\n", lookback))
    
    lstm_data <- prepare_lstm_data_fixed(
      data = data, gages_to_use = gages_to_use,
      sequence_length = lookback, forecast_horizon = forecast_horizon,
      dataset_name = paste(dataset_name, "LB", lookback)
    )
    
    if (is.null(lstm_data)) {
      cat(sprintf("  Skipping lookback=%d - insufficient data\n", lookback))
      results[[as.character(lookback)]] <- list(
        lookback = lookback, status = "insufficient_data", metrics = NULL
      )
      next
    }
    
    model <- build_lstm_model(
      sequence_length = lookback, n_features = lstm_data$n_features,
      forecast_horizon = forecast_horizon, lstm_units = c(128, 64, 32)
    )
    
    callbacks <- list(
      callback_early_stopping(monitor = "val_loss", patience = patience,
                              restore_best_weights = TRUE, verbose = 1),
      callback_reduce_lr_on_plateau(monitor = "val_loss", factor = 0.5,
                                    patience = 8, min_lr = 1e-6, verbose = 1)
    )
    
    batch_size <- min(32, max(8, floor(lstm_data$n_train / 10)))
    
    start_time <- Sys.time()
    history <- model |> fit(
      x = lstm_data$X_train, y = lstm_data$y_train,
      validation_data = list(lstm_data$X_val, lstm_data$y_val),
      epochs = epochs, batch_size = batch_size,
      callbacks = callbacks, verbose = 0
    )
    train_time <- difftime(Sys.time(), start_time, units = "mins")
    
    # Predictions and inverse transform
    val_pred_scaled <- predict(model, lstm_data$X_val)
    test_pred_scaled <- predict(model, lstm_data$X_test)
    
    val_pred <- val_pred_scaled * lstm_data$target_sd + lstm_data$target_mean
    test_pred <- test_pred_scaled * lstm_data$target_sd + lstm_data$target_mean
    val_actual <- lstm_data$y_val * lstm_data$target_sd + lstm_data$target_mean
    test_actual <- lstm_data$y_test * lstm_data$target_sd + lstm_data$target_mean
    
    # Metrics
    horizon_metrics <- data.frame(
      horizon = 1:forecast_horizon,
      val_rmse = sapply(1:forecast_horizon, function(h) sqrt(mean((val_pred[, h] - val_actual[, h])^2))),
      test_rmse = sapply(1:forecast_horizon, function(h) sqrt(mean((test_pred[, h] - test_actual[, h])^2)))
    )
    
    val_rmse_all <- sqrt(mean((val_pred - val_actual)^2))
    test_rmse_all <- sqrt(mean((test_pred - test_actual)^2))
    test_rmse_1step <- sqrt(mean((test_pred[, 1] - test_actual[, 1])^2))
    
    # Classification
    actual_class <- ifelse(test_actual[, 1] > threshold, "YES", "NO")
    pred_class <- ifelse(test_pred[, 1] > threshold, "YES", "NO")
    accuracy <- mean(actual_class == pred_class)
    
    TP <- sum(actual_class == "YES" & pred_class == "YES")
    FP <- sum(actual_class == "NO" & pred_class == "YES")
    FN <- sum(actual_class == "YES" & pred_class == "NO")
    TN <- sum(actual_class == "NO" & pred_class == "NO")
    
    precision <- ifelse((TP + FP) > 0, TP / (TP + FP), NA)
    recall <- ifelse((TP + FN) > 0, TP / (TP + FN), NA)
    f1 <- ifelse(!is.na(precision) & !is.na(recall) & (precision + recall) > 0,
                 2 * precision * recall / (precision + recall), NA)
    
    cat(sprintf("\n  Lookback %d: Test RMSE=%.4f, Accuracy=%.1f%%, F1=%.3f\n",
                lookback, test_rmse_all, accuracy * 100, f1))
    
    results[[as.character(lookback)]] <- list(
      lookback = lookback, status = "success", model = model,
      history = history, lstm_data = lstm_data, train_time = train_time,
      val_predictions = list(actual = val_actual, predicted = val_pred),
      test_predictions = list(actual = test_actual, predicted = test_pred,
                              dates = lstm_data$dates_test),
      horizon_metrics = horizon_metrics,
      summary_metrics = data.frame(
        lookback = lookback, val_rmse = val_rmse_all, test_rmse = test_rmse_all,
        test_rmse_1step = test_rmse_1step, accuracy = accuracy,
        precision = precision, recall = recall, f1 = f1
      ),
      confusion = table(Actual = actual_class, Predicted = pred_class)
    )
  }
  
  # Compare
  comparison <- do.call(rbind, lapply(results, function(x) {
    if (!is.null(x$summary_metrics)) x$summary_metrics else NULL
  }))
  
  if (!is.null(comparison) && nrow(comparison) > 0) {
    cat("\n=== LOOKBACK WINDOW COMPARISON ===\n")
    print(comparison |> arrange(test_rmse))
    best <- comparison |> slice_min(test_rmse, n = 1)
    cat(sprintf("\nBest lookback: %d days (Test RMSE: %.4f)\n", best$lookback, best$test_rmse))
  }
  
  return(list(
    results = results, comparison = comparison,
    best_lookback = if (!is.null(comparison)) comparison$lookback[which.min(comparison$test_rmse)] else NA,
    dataset_name = dataset_name
  ))
}
```

## Comprehensive LSTM Training Function

```{r lstm-comprehensive-training}
#' Train LSTM with continuous forecasting + binary classification

train_lstm_comprehensive <- function(lstm_data,
                                      dataset_name,
                                      threshold,
                                      epochs = 100,
                                      batch_size = 32,
                                      patience = 20) {
  
  if (is.null(lstm_data)) {
    cat(sprintf("Skipping %s - no data prepared\n", dataset_name))
    return(NULL)
  }
  
  cat(sprintf("\n%s\n", strrep("=", 70)))
  cat(sprintf("TRAINING LSTM: %s\n", dataset_name))
  cat(sprintf("Sequence length: %d, Forecast horizon: %d\n",
              lstm_data$sequence_length, lstm_data$forecast_horizon))
  cat(sprintf("%s\n", strrep("=", 70)))
  
  model <- build_lstm_model(
    sequence_length = lstm_data$sequence_length,
    n_features = lstm_data$n_features,
    forecast_horizon = lstm_data$forecast_horizon
  )
  
  callbacks <- list(
    callback_early_stopping(monitor = "val_loss", patience = patience,
                            restore_best_weights = TRUE, verbose = 1),
    callback_reduce_lr_on_plateau(monitor = "val_loss", factor = 0.5,
                                  patience = 10, min_lr = 1e-6, verbose = 1)
  )
  
  batch_size <- min(batch_size, max(8, floor(lstm_data$n_train / 4)))
  
  cat("\nTraining model...\n")
  start_time <- Sys.time()
  
  history <- model |> fit(
    x = lstm_data$X_train, y = lstm_data$y_train,
    validation_data = list(lstm_data$X_val, lstm_data$y_val),
    epochs = epochs, batch_size = batch_size,
    callbacks = callbacks, verbose = 1
  )
  
  training_time <- difftime(Sys.time(), start_time, units = "mins")
  cat(sprintf("\nTraining completed in %.1f minutes\n", training_time))
  
  # Predictions
  val_pred_scaled <- predict(model, lstm_data$X_val)
  test_pred_scaled <- predict(model, lstm_data$X_test)
  
  val_pred <- val_pred_scaled * lstm_data$target_sd + lstm_data$target_mean
  test_pred <- test_pred_scaled * lstm_data$target_sd + lstm_data$target_mean
  val_actual <- lstm_data$y_val * lstm_data$target_sd + lstm_data$target_mean
  test_actual <- lstm_data$y_test * lstm_data$target_sd + lstm_data$target_mean
  
  # Horizon metrics
  horizon_metrics <- data.frame(
    horizon_day = 1:lstm_data$forecast_horizon,
    val_rmse = sapply(1:lstm_data$forecast_horizon, function(h) sqrt(mean((val_pred[, h] - val_actual[, h])^2))),
    val_mae = sapply(1:lstm_data$forecast_horizon, function(h) mean(abs(val_pred[, h] - val_actual[, h]))),
    test_rmse = sapply(1:lstm_data$forecast_horizon, function(h) sqrt(mean((test_pred[, h] - test_actual[, h])^2))),
    test_mae = sapply(1:lstm_data$forecast_horizon, function(h) mean(abs(test_pred[, h] - test_actual[, h])))
  )
  
  # Overall metrics
  val_rmse_all <- sqrt(mean((val_pred - val_actual)^2))
  val_mae_all <- mean(abs(val_pred - val_actual))
  test_rmse_all <- sqrt(mean((test_pred - test_actual)^2))
  test_mae_all <- mean(abs(test_pred - test_actual))
  test_rmse_1step <- sqrt(mean((test_pred[, 1] - test_actual[, 1])^2))
  test_mae_1step <- mean(abs(test_pred[, 1] - test_actual[, 1]))
  
  # Intermediate horizons
  intermediate_days <- c(7, 14, 21, 30, 40)
  intermediate_days <- intermediate_days[intermediate_days <= lstm_data$forecast_horizon]
  
  intermediate_metrics <- data.frame(
    horizon = intermediate_days,
    test_rmse = sapply(intermediate_days, function(h) sqrt(mean((test_pred[, h] - test_actual[, h])^2))),
    test_mae = sapply(intermediate_days, function(h) mean(abs(test_pred[, h] - test_actual[, h])))
  )
  
  cat("\nIntermediate Horizon Metrics:\n")
  print(intermediate_metrics)
  
  # Classification at multiple horizons
  classification_results <- lapply(intermediate_days, function(h) {
    actual_class <- ifelse(test_actual[, h] > threshold, "YES", "NO")
    pred_class <- ifelse(test_pred[, h] > threshold, "YES", "NO")
    
    TP <- sum(actual_class == "YES" & pred_class == "YES")
    FP <- sum(actual_class == "NO" & pred_class == "YES")
    FN <- sum(actual_class == "YES" & pred_class == "NO")
    TN <- sum(actual_class == "NO" & pred_class == "NO")
    
    accuracy <- (TP + TN) / (TP + FP + FN + TN)
    precision <- ifelse((TP + FP) > 0, TP / (TP + FP), NA)
    recall <- ifelse((TP + FN) > 0, TP / (TP + FN), NA)
    f1 <- ifelse(!is.na(precision) & !is.na(recall) & (precision + recall) > 0,
                 2 * precision * recall / (precision + recall), NA)
    
    data.frame(horizon = h, accuracy = accuracy, precision = precision,
               recall = recall, f1 = f1, TP = TP, FP = FP, FN = FN, TN = TN)
  })
  
  classification_df <- do.call(rbind, classification_results)
  cat("\nBinary Classification Results:\n")
  print(classification_df |> select(horizon, accuracy, precision, recall, f1))
  
  summary_metrics <- data.frame(
    Dataset = dataset_name, Model = "LSTM",
    Sequence_Length = lstm_data$sequence_length,
    Forecast_Horizon = lstm_data$forecast_horizon,
    Val_RMSE = val_rmse_all, Val_MAE = val_mae_all,
    Test_RMSE_All = test_rmse_all, Test_MAE_All = test_mae_all,
    Test_RMSE_1Step = test_rmse_1step, Test_MAE_1Step = test_mae_1step,
    Accuracy_1Step = classification_df$accuracy[1],
    F1_1Step = classification_df$f1[1],
    Training_Time_Min = as.numeric(training_time)
  )
  
  cat("\n=== SUMMARY ===\n")
  cat(sprintf("  Val RMSE: %.4f, Test RMSE: %.4f\n", val_rmse_all, test_rmse_all))
  cat(sprintf("  1-Step - RMSE: %.4f, Accuracy: %.1f%%, F1: %.3f\n",
              test_rmse_1step, classification_df$accuracy[1] * 100, classification_df$f1[1]))
  
  return(list(
    model = model, history = history, dataset_name = dataset_name,
    training_time = training_time,
    predictions = list(
      val_actual = val_actual, val_predicted = val_pred,
      test_actual = test_actual, test_predicted = test_pred,
      dates_test = lstm_data$dates_test, dates_val = lstm_data$dates_val
    ),
    summary_metrics = summary_metrics,
    horizon_metrics = horizon_metrics,
    intermediate_metrics = intermediate_metrics,
    classification_metrics = classification_df,
    scalers = list(target_mean = lstm_data$target_mean, target_sd = lstm_data$target_sd),
    confusion_1step = table(
      Actual = ifelse(test_actual[, 1] > threshold, "YES", "NO"),
      Predicted = ifelse(test_pred[, 1] > threshold, "YES", "NO")
    )
  ))
}
```

## LSTM Validation Plots Function

```{r lstm-validation-plots}
#' Create comprehensive validation plots

create_lstm_validation_plots <- function(lstm_result, output_dir = "./Output/LSTM") {
  
  if (is.null(lstm_result)) return(NULL)
  
  dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
  
  dataset_name <- lstm_result$dataset_name
  preds <- lstm_result$predictions
  plots <- list()
  
  # 1. Validation time series
  val_df <- data.frame(
    date = as.Date(preds$dates_val),
    actual = preds$val_actual[, 1],
    predicted = preds$val_predicted[, 1]
  ) |> pivot_longer(cols = c(actual, predicted), names_to = "type", values_to = "value")
  
  plots$val_timeseries <- ggplot(val_df, aes(x = date, y = value, color = type)) +
    geom_line(linewidth = 0.8, alpha = 0.8) +
    geom_point(size = 1.5, alpha = 0.6) +
    scale_color_manual(values = c("actual" = "#2166AC", "predicted" = "#D6604D"),
                       labels = c("Actual", "Predicted")) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
    labs(title = paste(dataset_name, "- Validation Set (1-Step Ahead)"),
         x = "Date", y = "Shoaling Rate (ft/yr)", color = "") +
    theme_minimal() + theme(legend.position = "bottom")
  
  # 2. Test time series
  test_df <- data.frame(
    date = as.Date(preds$dates_test),
    actual = preds$test_actual[, 1],
    predicted = preds$test_predicted[, 1]
  ) |> pivot_longer(cols = c(actual, predicted), names_to = "type", values_to = "value")
  
  plots$test_timeseries <- ggplot(test_df, aes(x = date, y = value, color = type)) +
    geom_line(linewidth = 0.8, alpha = 0.8) +
    geom_point(size = 1.5, alpha = 0.6) +
    scale_color_manual(values = c("actual" = "#2166AC", "predicted" = "#D6604D"),
                       labels = c("Actual", "Predicted")) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
    labs(title = paste(dataset_name, "- Test Set Predictions (1-Step Ahead)"),
         x = "Date", y = "Shoaling Rate (ft/yr)", color = "") +
    theme_minimal() + theme(legend.position = "bottom")
  
  ggsave(file.path(output_dir, paste0(gsub(" ", "_", dataset_name), "_test_timeseries.png")),
         plots$test_timeseries, width = 12, height = 6)
  
  # 3. Scatter plot
  scatter_df <- data.frame(actual = preds$test_actual[, 1], predicted = preds$test_predicted[, 1])
  rmse <- sqrt(mean((scatter_df$predicted - scatter_df$actual)^2))
  r2 <- cor(scatter_df$actual, scatter_df$predicted)^2
  
  plots$scatter <- ggplot(scatter_df, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.6, size = 2.5, color = "#4575B4") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red", linewidth = 1) +
    geom_smooth(method = "lm", se = TRUE, color = "#D73027", fill = "#D73027", alpha = 0.2) +
    labs(title = paste(dataset_name, "- Predicted vs Actual"),
         subtitle = sprintf("RMSE: %.3f | RÂ²: %.3f", rmse, r2),
         x = "Actual (ft/yr)", y = "Predicted (ft/yr)") +
    theme_minimal()
  
  ggsave(file.path(output_dir, paste0(gsub(" ", "_", dataset_name), "_scatter.png")),
         plots$scatter, width = 8, height = 8)
  
  # 4. Horizon degradation
  horizon_df <- lstm_result$horizon_metrics
  
  plots$horizon <- ggplot(horizon_df, aes(x = horizon_day)) +
    geom_line(aes(y = test_rmse, color = "Test"), linewidth = 1.2) +
    geom_line(aes(y = val_rmse, color = "Validation"), linewidth = 1.2, linetype = "dashed") +
    geom_point(aes(y = test_rmse, color = "Test"), size = 2) +
    scale_color_manual(values = c("Test" = "#D6604D", "Validation" = "#2166AC")) +
    labs(title = paste(dataset_name, "- RMSE by Forecast Horizon"),
         x = "Forecast Horizon (days)", y = "RMSE (ft/yr)", color = "") +
    theme_minimal() + theme(legend.position = "bottom")
  
  ggsave(file.path(output_dir, paste0(gsub(" ", "_", dataset_name), "_horizon.png")),
         plots$horizon, width = 10, height = 6)
  
  # 5. Classification by horizon
  class_df <- lstm_result$classification_metrics
  if (!is.null(class_df) && nrow(class_df) > 0) {
    class_long <- class_df |>
      select(horizon, accuracy, precision, recall, f1) |>
      pivot_longer(cols = c(accuracy, precision, recall, f1), names_to = "metric", values_to = "value")
    
    plots$classification <- ggplot(class_long, aes(x = horizon, y = value, color = metric)) +
      geom_line(linewidth = 1.2) + geom_point(size = 3) +
      scale_color_viridis_d() +
      scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
      labs(title = paste(dataset_name, "- Classification by Horizon"),
           x = "Forecast Horizon (days)", y = "Score", color = "Metric") +
      theme_minimal() + theme(legend.position = "bottom")
    
    ggsave(file.path(output_dir, paste0(gsub(" ", "_", dataset_name), "_classification.png")),
           plots$classification, width = 10, height = 6)
  }
  
  # Combined summary
  plots$summary <- (plots$test_timeseries + plots$scatter) / (plots$horizon + plots$classification) +
    plot_annotation(title = paste(dataset_name, "- LSTM Model Summary"))
  
  ggsave(file.path(output_dir, paste0(gsub(" ", "_", dataset_name), "_summary.png")),
         plots$summary, width = 16, height = 14)
  
  cat(sprintf("\nPlots saved to %s\n", output_dir))
  return(plots)
}
```

## Pool-Level LSTM Function

```{r lstm-pool-function}
#' Train LSTM for a specific pool

train_pool_lstm_fixed <- function(data, pool_name, river_code, pool_gage_mapping,
                                  threshold, sequence_length = 30, forecast_horizon = 40,
                                  min_samples = 150, epochs = 75, patience = 15) {
  
  key <- paste(river_code, pool_name, sep = "_")
  
  if (!key %in% names(pool_gage_mapping)) {
    return(list(pool = pool_name, river = river_code, status = "no_mapping", metrics = NULL))
  }
  
  pool_map <- pool_gage_mapping[[key]]
  river_filter <- pool_map$river_filter
  selected_gages <- pool_map$selected_gages
  
  pool_data <- data |>
    filter(pool == pool_name, river == river_filter) |>
    arrange(SurveyDateBefore)
  
  min_required <- sequence_length + forecast_horizon + 50
  
  if (nrow(pool_data) < max(min_samples, min_required)) {
    return(list(pool = pool_name, river = river_code, status = "insufficient_samples",
                n = nrow(pool_data), metrics = NULL))
  }
  
  cat(sprintf("\n--- LSTM Pool %s (%s): %d samples ---\n", pool_name, river_code, nrow(pool_data)))
  
  lstm_data <- prepare_lstm_data_fixed(
    data = pool_data, gages_to_use = selected_gages,
    sequence_length = sequence_length, forecast_horizon = forecast_horizon,
    dataset_name = paste("Pool", pool_name)
  )
  
  if (is.null(lstm_data)) {
    return(list(pool = pool_name, river = river_code, status = "data_prep_failed", metrics = NULL))
  }
  
  lstm_result <- tryCatch({
    train_lstm_comprehensive(
      lstm_data = lstm_data, dataset_name = paste("Pool", pool_name),
      threshold = threshold, epochs = epochs,
      batch_size = min(32, floor(lstm_data$n_train / 4)), patience = patience
    )
  }, error = function(e) {
    cat(sprintf("  LSTM training error: %s\n", e$message))
    return(NULL)
  })
  
  if (is.null(lstm_result)) {
    return(list(pool = pool_name, river = river_code, status = "training_failed", metrics = NULL))
  }
  
  lstm_result$pool <- pool_name
  lstm_result$river <- river_code
  lstm_result$status <- "success"
  lstm_result$n_samples <- nrow(pool_data)
  lstm_result$summary_metrics$Pool <- pool_name
  lstm_result$summary_metrics$River <- river_code
  lstm_result$summary_metrics$N_Samples <- nrow(pool_data)
  
  return(lstm_result)
}
```

## Test Lookback Windows - River Level

```{r test-lookback-windows}
cat("\n### TESTING MULTIPLE LOOKBACK WINDOWS ###\n")

# Test lookback windows for Illinois Waterway
IWW_lookback_results <- test_lookback_windows(
  data = IWW_data,
  gages_to_use = IWW_gages,
  lookback_windows = c(7, 14, 30, 60),
  forecast_horizon = 40,
  threshold = IWW_thresh,
  epochs = 75,
  dataset_name = "Illinois Waterway"
)

# Test lookback windows for Mississippi River
Miss_lookback_results <- test_lookback_windows(
  data = Miss_data,
  gages_to_use = Miss_gages,
  lookback_windows = c(7, 14, 30, 60),
  forecast_horizon = 40,
  threshold = Miss_thresh,
  epochs = 75,
  dataset_name = "Mississippi River"
)

# Save lookback comparison
lookback_comparison <- bind_rows(
  IWW_lookback_results$comparison |> mutate(River = "Illinois Waterway"),
  Miss_lookback_results$comparison |> mutate(River = "Mississippi River")
)

write_csv(lookback_comparison, "./Output/LSTM/Lookback_Comparison.csv")

cat("\n=== OPTIMAL LOOKBACK WINDOWS ===\n")
cat(sprintf("Illinois Waterway: %d days\n", IWW_lookback_results$best_lookback))
cat(sprintf("Mississippi River: %d days\n", Miss_lookback_results$best_lookback))
```

## Train River-Level LSTM Models

```{r train-lstm-river-models}
# Get optimal lookback or use default
iww_best_lb <- ifelse(!is.na(IWW_lookback_results$best_lookback), 
                      IWW_lookback_results$best_lookback, 30)
miss_best_lb <- ifelse(!is.na(Miss_lookback_results$best_lookback),
                       Miss_lookback_results$best_lookback, 30)

cat(sprintf("\nTraining with optimal lookbacks - IWW: %d, Miss: %d\n", iww_best_lb, miss_best_lb))

# Illinois Waterway
IWW_lstm_data <- prepare_lstm_data_fixed(
  data = IWW_data,
  gages_to_use = IWW_gages,
  sequence_length = iww_best_lb,
  forecast_horizon = 40,
  dataset_name = "Illinois Waterway"
)

IWW_lstm <- train_lstm_comprehensive(
  lstm_data = IWW_lstm_data,
  dataset_name = "Illinois Waterway",
  threshold = IWW_thresh,
  epochs = 100,
  patience = 20
)

# Mississippi River
Miss_lstm_data <- prepare_lstm_data_fixed(
  data = Miss_data,
  gages_to_use = Miss_gages,
  sequence_length = miss_best_lb,
  forecast_horizon = 40,
  dataset_name = "Mississippi River"
)

Miss_lstm <- train_lstm_comprehensive(
  lstm_data = Miss_lstm_data,
  dataset_name = "Mississippi River",
  threshold = Miss_thresh,
  epochs = 100,
  patience = 20
)

# Combined
Combined_lstm_data <- prepare_lstm_data_fixed(
  data = gage_CSAT_joined,
  gages_to_use = All_gages,
  sequence_length = 30,
  forecast_horizon = 40,
  dataset_name = "Combined"
)

Combined_lstm <- train_lstm_comprehensive(
  lstm_data = Combined_lstm_data,
  dataset_name = "Combined",
  threshold = comb_thresh,
  epochs = 100,
  patience = 20
)
```

## Generate LSTM Validation Plots

```{r lstm-generate-plots, fig.height=14, fig.width=16}
# Generate validation plots
IWW_lstm_plots <- create_lstm_validation_plots(IWW_lstm, "./Output/LSTM/IWW")
Miss_lstm_plots <- create_lstm_validation_plots(Miss_lstm, "./Output/LSTM/Miss")
Combined_lstm_plots <- create_lstm_validation_plots(Combined_lstm, "./Output/LSTM/Combined")

# Display summary plots
if (!is.null(IWW_lstm_plots$summary)) print(IWW_lstm_plots$summary)
if (!is.null(Miss_lstm_plots$summary)) print(Miss_lstm_plots$summary)
```

## Train Pool-Level LSTM Models

```{r train-lstm-pool-models}
# Filter pools with sufficient data for LSTM (>= 150 samples)
lstm_viable_pools <- viable_pools |>
  filter(n_samples >= 150)

cat(sprintf("Training LSTM for %d viable pools\n", nrow(lstm_viable_pools)))

pool_lstm_results <- list()

for (i in 1:nrow(lstm_viable_pools)) {
  pool_name <- lstm_viable_pools$pool[i]
  river_code <- lstm_viable_pools$river[i]
  
  pool_threshold <- pool_thresholds |>
    filter(pool == pool_name) |>
    pull(mean_rate)
  
  if (length(pool_threshold) == 0) {
    pool_threshold <- ifelse(river_code == "IL", IWW_thresh, Miss_thresh)
  }
  
  result <- train_pool_lstm_fixed(
    data = gage_CSAT_joined,
    pool_name = pool_name,
    river_code = river_code,
    pool_gage_mapping = pool_gage_mapping,
    threshold = pool_threshold,
    sequence_length = 30,
    forecast_horizon = 40,
    min_samples = 150,
    epochs = 75,
    patience = 15
  )
  
  key <- paste(river_code, pool_name, sep = "_")
  pool_lstm_results[[key]] <- result
  
  # Generate plots for successful models
  if (result$status == "success") {
    create_lstm_validation_plots(result, output_dir = paste0("./Output/LSTM/Pool_", pool_name))
  }
}

# Compile pool-level metrics
pool_lstm_metrics <- do.call(rbind, lapply(pool_lstm_results, function(x) {
  if (!is.null(x$summary_metrics)) x$summary_metrics else NULL
}))

cat("\n=== POOL LSTM RESULTS ===\n")
if (!is.null(pool_lstm_metrics) && nrow(pool_lstm_metrics) > 0) {
  print(pool_lstm_metrics |> 
          select(Pool, River, Test_RMSE_1Step, Accuracy_1Step, F1_1Step) |>
          arrange(Test_RMSE_1Step))
  
  write_csv(pool_lstm_metrics, "./Output/LSTM/Pool_Level_Metrics.csv")
}
```

## LSTM Results Summary

```{r lstm-results-summary}
cat("\n")
cat(strrep("=", 80), "\n")
cat("                         LSTM RESULTS SUMMARY                              \n")
cat(strrep("=", 80), "\n\n")

# Lookback comparison
cat("=== LOOKBACK WINDOW OPTIMIZATION ===\n")
print(lookback_comparison |> select(River, lookback, test_rmse, accuracy, f1) |> arrange(River, test_rmse))

# River-level results
cat("\n=== RIVER-LEVEL LSTM PERFORMANCE ===\n")
river_lstm_metrics <- bind_rows(
  if (!is.null(IWW_lstm)) IWW_lstm$summary_metrics,
  if (!is.null(Miss_lstm)) Miss_lstm$summary_metrics,
  if (!is.null(Combined_lstm)) Combined_lstm$summary_metrics
)

if (!is.null(river_lstm_metrics)) {
  print(river_lstm_metrics |> 
          select(Dataset, Sequence_Length, Test_RMSE_1Step, Accuracy_1Step, F1_1Step))
  
  write_csv(river_lstm_metrics, "./Output/LSTM/River_Level_Metrics.csv")
}

# Pool-level summary
cat("\n=== POOL-LEVEL LSTM PERFORMANCE ===\n")
if (!is.null(pool_lstm_metrics) && nrow(pool_lstm_metrics) > 0) {
  pool_summary <- pool_lstm_metrics |>
    group_by(River) |>
    summarise(
      N_Pools = n(),
      Avg_RMSE = round(mean(Test_RMSE_1Step, na.rm = TRUE), 3),
      Avg_Accuracy = round(mean(Accuracy_1Step, na.rm = TRUE) * 100, 1),
      Avg_F1 = round(mean(F1_1Step, na.rm = TRUE), 3),
      .groups = "drop"
    )
  print(pool_summary)
}

# Comparison with xGBoost
cat("\n=== LSTM vs xGBoost COMPARISON ===\n")
comparison_df <- data.frame(
  River = c("Illinois Waterway", "Mississippi River"),
  xGBoost_RMSE = c(IWW_xgb$metrics$Test_RMSE, Miss_xgb$metrics$Test_RMSE),
  LSTM_RMSE = c(
    ifelse(!is.null(IWW_lstm), IWW_lstm$summary_metrics$Test_RMSE_1Step, NA),
    ifelse(!is.null(Miss_lstm), Miss_lstm$summary_metrics$Test_RMSE_1Step, NA)
  ),
  xGBoost_Accuracy = c(IWW_xgb$metrics$Accuracy, Miss_xgb$metrics$Accuracy),
  LSTM_Accuracy = c(
    ifelse(!is.null(IWW_lstm), IWW_lstm$summary_metrics$Accuracy_1Step, NA),
    ifelse(!is.null(Miss_lstm), Miss_lstm$summary_metrics$Accuracy_1Step, NA)
  )
) |>
  mutate(
    RMSE_Winner = ifelse(xGBoost_RMSE < LSTM_RMSE, "xGBoost", "LSTM"),
    Accuracy_Winner = ifelse(xGBoost_Accuracy > LSTM_Accuracy, "xGBoost", "LSTM")
  )

print(comparison_df)

cat("\n=== KEY FINDINGS ===\n")
for (i in 1:nrow(comparison_df)) {
  cat(sprintf("\n%s:\n", comparison_df$River[i]))
  cat(sprintf("  Best regression model: %s (RMSE: %.4f)\n", 
              comparison_df$RMSE_Winner[i],
              min(comparison_df$xGBoost_RMSE[i], comparison_df$LSTM_RMSE[i], na.rm = TRUE)))
  cat(sprintf("  Best classification model: %s (Accuracy: %.1f%%)\n",
              comparison_df$Accuracy_Winner[i],
              max(comparison_df$xGBoost_Accuracy[i], comparison_df$LSTM_Accuracy[i], na.rm = TRUE) * 100))
}
```

## LSTM Horizon Analysis Plot

```{r lstm-horizon-analysis, fig.height=8, fig.width=12}
# Combine horizon metrics from all river-level models
horizon_data <- bind_rows(
  if (!is.null(IWW_lstm)) IWW_lstm$horizon_metrics |> mutate(Dataset = "Illinois Waterway"),
  if (!is.null(Miss_lstm)) Miss_lstm$horizon_metrics |> mutate(Dataset = "Mississippi River"),
  if (!is.null(Combined_lstm)) Combined_lstm$horizon_metrics |> mutate(Dataset = "Combined")
)

if (nrow(horizon_data) > 0) {
  p_horizon <- ggplot(horizon_data, aes(x = horizon_day, y = test_rmse, color = Dataset)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 2) +
    geom_vline(xintercept = c(7, 14, 21, 30, 40), linetype = "dashed", alpha = 0.3) +
    scale_color_viridis_d() +
    labs(
      title = "LSTM Forecast Error by Horizon",
      subtitle = "Error increases with forecast distance (vertical lines mark key horizons)",
      x = "Forecast Horizon (days ahead)",
      y = "RMSE (ft/yr)"
    ) +
    theme_minimal() +
    theme(legend.position = "bottom")
  
  print(p_horizon)
  ggsave("./Output/LSTM/Horizon_Performance_All.png", width = 12, height = 8)
}
```


# Compile Model Results 
```{r compile-results}
# River-level regression results
river_results <- bind_rows(
IWW_baselines$results |> mutate(River = "Illinois Waterway", Type = "Baseline"),
Miss_baselines$results |> mutate(River = "Mississippi River", Type = "Baseline"),
Combined_baselines$results |> mutate(River = "Combined", Type = "Baseline"),
IWW_xgb$metrics |>
  select(Dataset, Model, Test_RMSE, Test_MAE) |>
  mutate(River = "Illinois Waterway", Type = "ML"),
Miss_xgb$metrics |>
  select(Dataset, Model, Test_RMSE, Test_MAE) |>
  mutate(River = "Mississippi River", Type = "ML"),
Combined_xgb$metrics |>
  select(Dataset, Model, Test_RMSE, Test_MAE) |>
  mutate(River = "Combined", Type = "ML")
)

# Add LSTM results
if (!is.null(IWW_lstm)) {
river_results <- bind_rows(
  river_results,
  IWW_lstm$metrics |>
    mutate(Model = "LSTM", Test_RMSE = Test_RMSE_1Step, Test_MAE = Test_MAE_1Step,
           River = "Illinois Waterway", Type = "ML") |>
    select(Dataset, Model, Test_RMSE, Test_MAE, River, Type)
)
}

if (!is.null(Miss_lstm)) {
river_results <- bind_rows(
  river_results,
  Miss_lstm$metrics |>
    mutate(Model = "LSTM", Test_RMSE = Test_RMSE_1Step, Test_MAE = Test_MAE_1Step,
           River = "Mississippi River", Type = "ML") |>
    select(Dataset, Model, Test_RMSE, Test_MAE, River, Type)
)
}

if (!is.null(Combined_lstm)) {
river_results <- bind_rows(
  river_results,
  Combined_lstm$metrics |>
    mutate(Model = "LSTM", Test_RMSE = Test_RMSE_1Step, Test_MAE = Test_MAE_1Step,
           River = "Combined", Type = "ML") |>
    select(Dataset, Model, Test_RMSE, Test_MAE, River, Type)
)
}

# Classification results
classification_results <- bind_rows(
IWW_xgb$metrics |> select(Dataset, Accuracy, Precision, Recall, F1_Score) |> mutate(Model = "xGBoost"),
Miss_xgb$metrics |> select(Dataset, Accuracy, Precision, Recall, F1_Score) |> mutate(Model = "xGBoost"),
Combined_xgb$metrics |> select(Dataset, Accuracy, Precision, Recall, F1_Score) |> mutate(Model = "xGBoost")
)

if (!is.null(IWW_lstm)) {
classification_results <- bind_rows(
  classification_results,
  IWW_lstm$metrics |> select(Dataset, Accuracy, Precision, Recall, F1_Score) |> mutate(Model = "LSTM")
)
}

if (!is.null(Miss_lstm)) {
classification_results <- bind_rows(
  classification_results,
  Miss_lstm$metrics |> select(Dataset, Accuracy, Precision, Recall, F1_Score) |> mutate(Model = "LSTM")
)
}

if (!is.null(Combined_lstm)) {
classification_results <- bind_rows(
  classification_results,
  Combined_lstm$metrics |> select(Dataset, Accuracy, Precision, Recall, F1_Score) |> mutate(Model = "LSTM")
)
}

cat("=== River-Level Regression Results ===\n")
print(river_results |> arrange(River, Test_RMSE))

cat("\n=== Classification Results ===\n")
print(classification_results |> arrange(Dataset, desc(F1_Score)))
```

# Model Performance Summary
```{r performance-summary}
cat("\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n")
cat("â                    COMPREHENSIVE RESULTS SUMMARY                        â\n")
cat("â âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ£\n")

for (river in c("Illinois Waterway", "Mississippi River", "Combined")) {

cat(sprintf("â %s:\n", river))

river_data <- river_results |>
  filter(River == river) |>
  arrange(Test_RMSE)

best_baseline <- river_data |> filter(Type == "Baseline") |> dplyr::slice(1)
best_ml <- river_data |> filter(Type == "ML") |> dplyr::slice(1)

if (nrow(best_ml) > 0) {
  improvement <- (best_baseline$Test_RMSE - best_ml$Test_RMSE) / best_baseline$Test_RMSE * 100
  
  cat(sprintf("â   Best Baseline: %s (RMSE: %.4f)\n", best_baseline$Model, best_baseline$Test_RMSE))
  cat(sprintf("â   Best ML Model: %s (RMSE: %.4f)\n", best_ml$Model, best_ml$Test_RMSE))
  cat(sprintf("â   Improvement: %.1f%%\n", improvement))
}

cat("â\n")
}

cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n")
```
#Pool Level Results
```{r}
# ============================================================================
# POOL-LEVEL MODEL RESULTS AND COMPARISONS
# ============================================================================

# ----------------------------------------------------------------------------
# 1. POOL XGBOOST SUMMARY
# ----------------------------------------------------------------------------

cat("\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n")
cat("â                    POOL-LEVEL XGBOOST RESULTS                          â\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n\n")

if (!is.null(pool_xgb_metrics) && nrow(pool_xgb_metrics) > 0) {
  
  # Summary statistics by river
  pool_xgb_summary <- pool_xgb_metrics |>
    group_by(River) |>
    summarise(
      N_Pools = n(),
      Avg_RMSE = round(mean(Test_RMSE, na.rm = TRUE), 3),
      Min_RMSE = round(min(Test_RMSE, na.rm = TRUE), 3),
      Max_RMSE = round(max(Test_RMSE, na.rm = TRUE), 3),
      Avg_R2 = round(mean(Test_R2, na.rm = TRUE), 3),
      Avg_Accuracy = round(mean(Accuracy, na.rm = TRUE) * 100, 1),
      Avg_F1 = round(mean(F1_Score, na.rm = TRUE), 3),
      .groups = "drop"
    )
  
  cat("=== Summary by River System ===\n")
  print(pool_xgb_summary)
  
  # Best performing pools
  cat("\n=== Top 5 Best Performing Pools (by RMSE) ===\n")
  best_pools <- pool_xgb_metrics |>
    arrange(Test_RMSE) |>
    head(5) |>
    select(Pool, River, N_Samples, Test_RMSE, Test_R2, Accuracy, F1_Score) |>
    mutate(
      Test_RMSE = round(Test_RMSE, 3),
      Test_R2 = round(Test_R2, 3),
      Accuracy = round(Accuracy * 100, 1),
      F1_Score = round(F1_Score, 3)
    )
  print(best_pools)
  
  # Worst performing pools
  cat("\n=== Top 5 Worst Performing Pools (by RMSE) ===\n")
  worst_pools <- pool_xgb_metrics |>
    arrange(desc(Test_RMSE)) |>
    head(5) |>
    select(Pool, River, N_Samples, Test_RMSE, Test_R2, Accuracy, F1_Score) |>
    mutate(
      Test_RMSE = round(Test_RMSE, 3),
      Test_R2 = round(Test_R2, 3),
      Accuracy = round(Accuracy * 100, 1),
      F1_Score = round(F1_Score, 3)
    )
  print(worst_pools)
  
  # Classification performance
  cat("\n=== Classification Performance by Pool ===\n")
  class_summary <- pool_xgb_metrics |>
    arrange(desc(F1_Score)) |>
    select(Pool, River, Accuracy, Precision, Recall, F1_Score) |>
    mutate(
      Accuracy = round(Accuracy * 100, 1),
      Precision = round(Precision, 3),
      Recall = round(Recall, 3),
      F1_Score = round(F1_Score, 3)
    )
  print(class_summary)
  
} else {
  cat("No pool-level xGBoost results available\n")
}

# ----------------------------------------------------------------------------
# 2. POOL LSTM SUMMARY (if available)
# ----------------------------------------------------------------------------

cat("\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n")
cat("â                    POOL-LEVEL LSTM RESULTS                             â\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n\n")

if (!is.null(pool_lstm_metrics) && nrow(pool_lstm_metrics) > 0) {
  
  pool_lstm_summary <- pool_lstm_metrics |>
    group_by(River) |>
    summarise(
      N_Pools = n(),
      Avg_RMSE_1Step = round(mean(Test_RMSE_1Step, na.rm = TRUE), 3),
      Min_RMSE_1Step = round(min(Test_RMSE_1Step, na.rm = TRUE), 3),
      Max_RMSE_1Step = round(max(Test_RMSE_1Step, na.rm = TRUE), 3),
      Avg_Accuracy = round(mean(Accuracy, na.rm = TRUE) * 100, 1),
      Avg_F1 = round(mean(F1_Score, na.rm = TRUE), 3),
      .groups = "drop"
    )
  
  cat("=== LSTM Summary by River System ===\n")
  print(pool_lstm_summary)
  
  cat("\n=== Pool LSTM Detailed Results ===\n")
  print(pool_lstm_metrics |> 
          select(Pool, River, Test_RMSE_1Step, Accuracy, F1_Score) |>
          mutate(
            Test_RMSE_1Step = round(Test_RMSE_1Step, 3),
            Accuracy = round(Accuracy * 100, 1),
            F1_Score = round(F1_Score, 3)
          ) |>
          arrange(Test_RMSE_1Step))
  
} else {
  cat("No pool-level LSTM results available (requires >= 150 samples per pool)\n")
}

# ----------------------------------------------------------------------------
# 3. POOL vs RIVER-LEVEL COMPARISON
# ----------------------------------------------------------------------------

cat("\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n")
cat("â                 POOL-LEVEL vs RIVER-LEVEL COMPARISON                   â\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n\n")

# Create comparison table
comparison_data <- data.frame(
  Level = c("River-Level", "River-Level", "Pool-Level Avg", "Pool-Level Avg"),
  River = c("Illinois Waterway", "Mississippi River", "Illinois Waterway", "Mississippi River"),
  Model = rep("xGBoost", 4),
  RMSE = c(
    IWW_xgb$metrics$Test_RMSE,
    Miss_xgb$metrics$Test_RMSE,
    ifelse(!is.null(pool_xgb_metrics), 
           mean(pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "IL"], na.rm = TRUE), 
           NA),
    ifelse(!is.null(pool_xgb_metrics), 
           mean(pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "UM"], na.rm = TRUE), 
           NA)
  ),
  Accuracy = c(
    IWW_xgb$metrics$Accuracy,
    Miss_xgb$metrics$Accuracy,
    ifelse(!is.null(pool_xgb_metrics), 
           mean(pool_xgb_metrics$Accuracy[pool_xgb_metrics$River == "IL"], na.rm = TRUE), 
           NA),
    ifelse(!is.null(pool_xgb_metrics), 
           mean(pool_xgb_metrics$Accuracy[pool_xgb_metrics$River == "UM"], na.rm = TRUE), 
           NA)
  )
) |>
  mutate(
    RMSE = round(RMSE, 3),
    Accuracy = round(Accuracy * 100, 1)
  )

cat("=== xGBoost: River-Level vs Pool-Level ===\n")
print(comparison_data)

# Calculate if pool-level is better or worse
if (!is.null(pool_xgb_metrics)) {
  cat("\n=== Performance Difference (Pool - River) ===\n")
  
  iww_diff <- mean(pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "IL"], na.rm = TRUE) - 
              IWW_xgb$metrics$Test_RMSE
  miss_diff <- mean(pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "UM"], na.rm = TRUE) - 
               Miss_xgb$metrics$Test_RMSE
  
  cat(sprintf("  Illinois Waterway: %+.3f RMSE (%s)\n", 
              iww_diff, 
              ifelse(iww_diff < 0, "Pool-level BETTER", "River-level BETTER")))
  cat(sprintf("  Mississippi River: %+.3f RMSE (%s)\n", 
              miss_diff, 
              ifelse(miss_diff < 0, "Pool-level BETTER", "River-level BETTER")))
}

# ----------------------------------------------------------------------------
# 4. VISUALIZATIONS
# ----------------------------------------------------------------------------

# Plot 1: Pool RMSE Distribution by River
if (!is.null(pool_xgb_metrics) && nrow(pool_xgb_metrics) > 0) {
  
  p_pool_rmse <- pool_xgb_metrics |>
    mutate(river_label = ifelse(River == "IL", "Illinois Waterway", "Mississippi River")) |>
    ggplot(aes(x = reorder(Pool, Test_RMSE), y = Test_RMSE, fill = river_label)) +
    geom_col(alpha = 0.8) +
    geom_hline(data = data.frame(
      river_label = c("Illinois Waterway", "Mississippi River"),
      yint = c(IWW_xgb$metrics$Test_RMSE, Miss_xgb$metrics$Test_RMSE)
    ), aes(yintercept = yint), linetype = "dashed", color = "red", linewidth = 1) +
    facet_wrap(~river_label, scales = "free_x") +
    scale_fill_manual(values = c("Illinois Waterway" = "orange", "Mississippi River" = "dodgerblue")) +
    labs(
      title = "Pool-Level xGBoost RMSE Performance",
      subtitle = "Dashed line = River-level model RMSE",
      x = "Pool",
      y = "Test RMSE (ft/yr)",
      fill = "River"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none"
    )
  
  print(p_pool_rmse)
  ggsave("./Output/Pool_Models/Pool_RMSE_Comparison.png", width = 14, height = 8)
  
  # Plot 2: Pool Classification Accuracy
  p_pool_accuracy <- pool_xgb_metrics |>
    mutate(river_label = ifelse(River == "IL", "Illinois Waterway", "Mississippi River")) |>
    ggplot(aes(x = reorder(Pool, Accuracy), y = Accuracy * 100, fill = river_label)) +
    geom_col(alpha = 0.8) +
    geom_hline(yintercept = 50, linetype = "dashed", color = "gray50") +
    facet_wrap(~river_label, scales = "free_x") +
    scale_fill_manual(values = c("Illinois Waterway" = "orange", "Mississippi River" = "dodgerblue")) +
    labs(
      title = "Pool-Level Classification Accuracy",
      subtitle = "Dashed line = 50% (random baseline)",
      x = "Pool",
      y = "Accuracy (%)",
      fill = "River"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none"
    )
  
  print(p_pool_accuracy)
  ggsave("./Output/Pool_Models/Pool_Accuracy_Comparison.png", width = 14, height = 8)
  
  # Plot 3: Sample Size vs Performance
  p_samples_vs_rmse <- pool_xgb_metrics |>
    mutate(river_label = ifelse(River == "IL", "Illinois Waterway", "Mississippi River")) |>
    ggplot(aes(x = N_Samples, y = Test_RMSE, color = river_label)) +
    geom_point(size = 4, alpha = 0.7) +
    geom_text(aes(label = Pool), hjust = -0.2, vjust = 0.5, size = 3) +
    geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
    scale_color_manual(values = c("Illinois Waterway" = "orange", "Mississippi River" = "dodgerblue")) +
    labs(
      title = "Sample Size vs Model Performance",
      subtitle = "Does more data improve predictions?",
      x = "Number of Training Samples",
      y = "Test RMSE (ft/yr)",
      color = "River"
    ) +
    theme_minimal() +
    theme(legend.position = "bottom")
  
  print(p_samples_vs_rmse)
  ggsave("./Output/Pool_Models/Samples_vs_RMSE.png", width = 12, height = 8)
  
  # Plot 4: RMSE vs RÂ² Scatter
  p_rmse_r2 <- pool_xgb_metrics |>
    mutate(river_label = ifelse(River == "IL", "Illinois Waterway", "Mississippi River")) |>
    ggplot(aes(x = Test_RMSE, y = Test_R2, color = river_label, size = N_Samples)) +
    geom_point(alpha = 0.7) +
    geom_text(aes(label = Pool), hjust = -0.2, vjust = 0.5, size = 3) +
    scale_color_manual(values = c("Illinois Waterway" = "orange", "Mississippi River" = "dodgerblue")) +
    scale_size_continuous(range = c(3, 10)) +
    labs(
      title = "Pool Model Performance: RMSE vs RÂ²",
      x = "Test RMSE (ft/yr)",
      y = "RÂ²",
      color = "River",
      size = "N Samples"
    ) +
    theme_minimal() +
    theme(legend.position = "right")
  
  print(p_rmse_r2)
  ggsave("./Output/Pool_Models/RMSE_vs_R2.png", width = 12, height = 8)
}

# ----------------------------------------------------------------------------
# 5. COMPREHENSIVE RESULTS TABLE
# ----------------------------------------------------------------------------

cat("\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n")
cat("â                 COMPREHENSIVE POOL RESULTS TABLE                       â\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n\n")

if (!is.null(pool_xgb_metrics)) {
  
  comprehensive_pool_results <- pool_xgb_metrics |>
    mutate(
      river_label = ifelse(River == "IL", "Illinois Waterway", "Mississippi River")
    ) |>
    select(
      Pool, 
      River = river_label,
      N_Samples,
      N_Gages,
      RMSE = Test_RMSE,
      MAE = Test_MAE,
      R2 = Test_R2,
      Accuracy,
      Precision,
      Recall,
      F1 = F1_Score
    ) |>
    mutate(
      RMSE = round(RMSE, 3),
      MAE = round(MAE, 3),
      R2 = round(R2, 3),
      Accuracy = round(Accuracy * 100, 1),
      Precision = round(Precision, 3),
      Recall = round(Recall, 3),
      F1 = round(F1, 3)
    ) |>
    arrange(River, RMSE)
  
  print(comprehensive_pool_results)
  
  # Save to CSV
  write_csv(comprehensive_pool_results, "./Output/Pool_Models/Comprehensive_Pool_Results.csv")
  cat("\nResults saved to ./Output/Pool_Models/Comprehensive_Pool_Results.csv\n")
}

# ----------------------------------------------------------------------------
# 6. STATISTICAL TESTS
# ----------------------------------------------------------------------------

cat("\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n")
cat("â                    STATISTICAL COMPARISONS                             â\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n\n")

if (!is.null(pool_xgb_metrics) && nrow(pool_xgb_metrics) > 1) {
  
  # Test if IWW and Miss pools have different RMSE
  iww_rmse <- pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "IL"]
  miss_rmse <- pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "UM"]
  
  if (length(iww_rmse) >= 2 && length(miss_rmse) >= 2) {
    t_test <- t.test(iww_rmse, miss_rmse)
    
    cat("=== T-Test: IWW vs Mississippi Pool RMSE ===\n")
    cat(sprintf("  IWW Mean RMSE: %.3f (n=%d)\n", mean(iww_rmse), length(iww_rmse)))
    cat(sprintf("  Miss Mean RMSE: %.3f (n=%d)\n", mean(miss_rmse), length(miss_rmse)))
    cat(sprintf("  T-statistic: %.3f\n", t_test$statistic))
    cat(sprintf("  P-value: %.4f\n", t_test$p.value))
    cat(sprintf("  Significant difference (p<0.05): %s\n", 
                ifelse(t_test$p.value < 0.05, "YES", "NO")))
  }
  
  # Correlation: Sample size vs RMSE
  cor_test <- cor.test(pool_xgb_metrics$N_Samples, pool_xgb_metrics$Test_RMSE)
  
  cat("\n=== Correlation: Sample Size vs RMSE ===\n")
  cat(sprintf("  Correlation: %.3f\n", cor_test$estimate))
  cat(sprintf("  P-value: %.4f\n", cor_test$p.value))
  cat(sprintf("  Interpretation: %s\n", 
              ifelse(cor_test$estimate < 0, 
                     "More samples â Lower RMSE (better)", 
                     "More samples â Higher RMSE (unexpected)")))
}

# ----------------------------------------------------------------------------
# 7. KEY FINDINGS SUMMARY
# ----------------------------------------------------------------------------

cat("\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n")
cat("â                       KEY FINDINGS SUMMARY                             â\n")
cat("ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ\n\n")

if (!is.null(pool_xgb_metrics)) {
  
  # Best overall pool
  best_pool <- pool_xgb_metrics |> slice_min(Test_RMSE, n = 1)
  worst_pool <- pool_xgb_metrics |> slice_max(Test_RMSE, n = 1)
  best_class_pool <- pool_xgb_metrics |> slice_max(F1_Score, n = 1)
  
  cat(sprintf("1. BEST REGRESSION POOL: %s (%s)\n", best_pool$Pool, 
              ifelse(best_pool$River == "IL", "Illinois Waterway", "Mississippi River")))
  cat(sprintf("   - RMSE: %.3f ft/yr, RÂ²: %.3f\n", best_pool$Test_RMSE, best_pool$Test_R2))
  
  cat(sprintf("\n2. WORST REGRESSION POOL: %s (%s)\n", worst_pool$Pool,
              ifelse(worst_pool$River == "IL", "Illinois Waterway", "Mississippi River")))
  cat(sprintf("   - RMSE: %.3f ft/yr, RÂ²: %.3f\n", worst_pool$Test_RMSE, worst_pool$Test_R2))
  
  cat(sprintf("\n3. BEST CLASSIFICATION POOL: %s (%s)\n", best_class_pool$Pool,
              ifelse(best_class_pool$River == "IL", "Illinois Waterway", "Mississippi River")))
  cat(sprintf("   - Accuracy: %.1f%%, F1: %.3f\n", best_class_pool$Accuracy * 100, best_class_pool$F1_Score))
  
  # River comparison
  iww_avg_rmse <- mean(pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "IL"], na.rm = TRUE)
  miss_avg_rmse <- mean(pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "UM"], na.rm = TRUE)
  
  cat(sprintf("\n4. RIVER COMPARISON:\n"))
  cat(sprintf("   - Illinois Waterway avg pool RMSE: %.3f ft/yr\n", iww_avg_rmse))
  cat(sprintf("   - Mississippi River avg pool RMSE: %.3f ft/yr\n", miss_avg_rmse))
  cat(sprintf("   - %s pools are more predictable on average\n",
              ifelse(iww_avg_rmse < miss_avg_rmse, "Illinois Waterway", "Mississippi River")))
  
  # Pool vs River level
  cat(sprintf("\n5. POOL vs RIVER-LEVEL:\n"))
  cat(sprintf("   - %d of %d pools outperform river-level model (IWW)\n",
              sum(pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "IL"] < IWW_xgb$metrics$Test_RMSE),
              sum(pool_xgb_metrics$River == "IL")))
  cat(sprintf("   - %d of %d pools outperform river-level model (Miss)\n",
              sum(pool_xgb_metrics$Test_RMSE[pool_xgb_metrics$River == "UM"] < Miss_xgb$metrics$Test_RMSE),
              sum(pool_xgb_metrics$River == "UM")))
}
```



# Visualizations

## Prediction Plots

```{r prediction-plots, fig.height=10}
# Function to create time series comparison
plot_predictions <- function(pred_df, dataset_name, model_type) {

plot_data <- pred_df |>
  select(date, actual, predicted) |>
  pivot_longer(cols = c(actual, predicted), names_to = "type", values_to = "shoaling_rate") |>
  mutate(type = factor(type, levels = c("actual", "predicted"), labels = c("Actual", "Predicted")))

ggplot(plot_data, aes(x = date, y = shoaling_rate, color = type)) +
  geom_line(linewidth = 0.8, alpha = 0.8) +
  geom_point(size = 1.5, alpha = 0.6) +
  scale_color_manual(values = c("Actual" = "#2166AC", "Predicted" = "#D6604D")) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  labs(
    title = sprintf("%s - %s Model", dataset_name, model_type),
    x = "Date", y = "Annual Shoaling Rate (ft/yr)", color = ""
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
}

# Function for scatter plot
plot_scatter <- function(pred_df, dataset_name, model_type) {

rmse <- sqrt(mean((pred_df$predicted - pred_df$actual)^2))
mae <- mean(abs(pred_df$predicted - pred_df$actual))
r2 <- cor(pred_df$actual, pred_df$predicted)^2

ggplot(pred_df, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.6, size = 2.5, color = "#4575B4") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red", linewidth = 1) +
  geom_smooth(method = "lm", se = TRUE, color = "#D73027", fill = "#D73027", alpha = 0.2) +
  labs(
    title = sprintf("%s - %s", dataset_name, model_type),
    subtitle = sprintf("RMSE: %.3f | MAE: %.3f | RÂ²: %.3f", rmse, mae, r2),
    x = "Actual (ft/yr)", y = "Predicted (ft/yr)"
  ) +
  theme_minimal()
}

# xGBoost plots
p_iww_ts <- plot_predictions(IWW_xgb$predictions, "Illinois Waterway", "xGBoost")
p_miss_ts <- plot_predictions(Miss_xgb$predictions, "Mississippi River", "xGBoost")

p_iww_sc <- plot_scatter(IWW_xgb$predictions, "Illinois Waterway", "xGBoost")
p_miss_sc <- plot_scatter(Miss_xgb$predictions, "Mississippi River", "xGBoost")

(p_iww_ts + p_miss_ts) / (p_iww_sc + p_miss_sc)

ggsave("./Output/Comparisons/xGBoost_Predictions.png", width = 14, height = 12)

# LSTM plots (if available)
if (!is.null(IWW_lstm) && !is.null(Miss_lstm)) {

IWW_lstm_pred_df <- data.frame(
  actual = IWW_lstm$predictions$actual_1step,
  predicted = IWW_lstm$predictions$predicted_1step,
  date = as.Date(IWW_lstm$predictions$dates)
)

Miss_lstm_pred_df <- data.frame(
  actual = Miss_lstm$predictions$actual_1step,
  predicted = Miss_lstm$predictions$predicted_1step,
  date = as.Date(Miss_lstm$predictions$dates)
)

p_iww_lstm_ts <- plot_predictions(IWW_lstm_pred_df, "Illinois Waterway", "LSTM")
p_miss_lstm_ts <- plot_predictions(Miss_lstm_pred_df, "Mississippi River", "LSTM")

p_iww_lstm_sc <- plot_scatter(IWW_lstm_pred_df, "Illinois Waterway", "LSTM")
p_miss_lstm_sc <- plot_scatter(Miss_lstm_pred_df, "Mississippi River", "LSTM")

print(p_iww_lstm_ts + p_miss_lstm_ts)
print(p_iww_lstm_sc + p_miss_lstm_sc)
ggsave("./Output/Comparisons/LSTM_Predictions.png", width = 14, height = 12)
}
```

## LSTM Horizon Analysis
```{r lstm-horizon-plot, fig.height=6}
if (!is.null(IWW_lstm) && !is.null(Miss_lstm)) {

horizon_data <- bind_rows(
  IWW_lstm$horizon_metrics |> mutate(Dataset = "Illinois Waterway"),
  Miss_lstm$horizon_metrics |> mutate(Dataset = "Mississippi River")
)

if (!is.null(Combined_lstm)) {
  horizon_data <- bind_rows(horizon_data,
    Combined_lstm$horizon_metrics |> mutate(Dataset = "Combined"))
}

ggplot(horizon_data, aes(x = Horizon, y = RMSE, color = Dataset)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 2) +
  scale_color_viridis_d() +
  labs(
    title = "LSTM Performance by Forecast Horizon",
    subtitle = "RMSE increases with forecast distance",
    x = "Forecast Horizon (observations ahead)",
    y = "RMSE (ft/yr)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

ggsave("./Output/LSTM/Horizon_Performance.png", width = 10, height = 6)
}
```

##  Pool Performance Map

```{r pool-map, fig.height=10}
if (!is.null(pool_xgb_metrics)) {
pool_info <- pool_info |>
  mutate(center_rm = (min_rm + max_rm) / 2)|>
    mutate(
    x_pos = ifelse(river == "IL", 2, 1)
  )


pool_map_data <- pool_xgb_metrics |>
  left_join(pool_info |> select(pool, river, center_rm,x_pos),
            by = c("Pool" = "pool", "River" = "river"))

ggplot(pool_map_data, aes(x = x_pos, y = center_rm)) +
  geom_line(aes(group = River), color = "lightblue", linewidth = 8, alpha = 0.4) +
  geom_point(aes(size = N_Samples, color = Test_RMSE), alpha = 0.8) +
  geom_text(aes(label = Pool), hjust = -0.3, size = 3) +
  scale_color_viridis_c(option = "plasma", direction = -1, name = "RMSE\n(ft/yr)") +
  scale_size_continuous(range = c(3, 12), name = "N Samples") +
  scale_x_continuous(breaks = c(1, 2),
                    labels = c("Mississippi\nRiver", "Illinois\nWaterway"),
                    limits = c(0.5, 2.8)) +
  labs(
    title = "Pool-Level xGBoost Model Performance",
    subtitle = "By river mile (upstream = higher values)",
    y = "River Mile", x = ""
  ) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank())

ggsave("./Output/Maps/Pool_Performance_Schematic.png", width = 10, height = 12)
}
```

# Dredging Priority Map
```{r}
create_dredging_prediction_map <- function(pool_xgb_results, 
                                           pool_info,
                                           gage_CSAT_joined,
                                           threshold_df) {
  
  # Collect predictions in a list first
  prediction_list <- list()
  
  for (key in names(pool_xgb_results)) {
    
    result <- pool_xgb_results[[key]]
    
    # Skip if no model or not successful
    if (is.null(result$model) || result$status != "success") {
      cat(sprintf("  Skipping %s: status = %s\n", key, result$status))
      next
    }
    
    pool_name <- result$pool
    river_code <- result$river
    gages_used <- result$gages_used
    
    # Get most recent data for this pool
    recent_data <- gage_CSAT_joined |>
      filter(pool == pool_name, river == river_code) |>
      arrange(desc(SurveyDateBefore)) |>
      dplyr::slice(1)
    
    if (nrow(recent_data) == 0) {
      cat(sprintf("  Skipping %s: no data found\n", key))
      next
    }
    
    # Select only the features the model needs
    model_features <- c("WeekOfYear", "DaysBetween", gages_used)
    available_features <- intersect(model_features, names(recent_data))
    
    # Create prediction dataset with only required features
    pred_data <- recent_data |>
      select(all_of(available_features))
    
    # Check for NAs
    if (any(is.na(pred_data))) {
      cat(sprintf("  Skipping %s: NA values in features\n", key))
      next
    }
    
    # Make prediction
    pred <- tryCatch({
      p <- predict(result$model, newdata = pred_data)
      if (length(p) == 0 || is.null(p)) NA else as.numeric(p)
    }, error = function(e) {
      cat(sprintf("  Skipping %s: prediction error - %s\n", key, e$message))
      NA
    })
    
    if (is.na(pred)) next
    
    # Get threshold
    thresh <- threshold_df |>
      filter(river == river_code) |>
      pull(mean_rate)
    
    if (length(thresh) == 0) thresh <- comb_thresh
    
    # Add to list
    prediction_list[[key]] <- data.frame(
      Pool = pool_name,
      River = river_code,
      Last_Survey = recent_data$SurveyDateBefore,
      Actual_Rate = recent_data$AnnualShoalingRate_ftperyr,
      Predicted_Rate = pred,
      Threshold = thresh,
      Dredge_Needed = pred > thresh,
      Urgency = case_when(
        pred > thresh * 2 ~ "HIGH",
        pred > thresh ~ "MODERATE", 
        pred > 0 ~ "LOW",
        TRUE ~ "NONE"
      )
    )
    
    cat(sprintf("  Success: %s - Predicted: %.2f\n", key, pred))
  }
  
  # Check if we got any predictions
  if (length(prediction_list) == 0) {
    warning("No predictions generated")
    return(NULL)
  }
  
  # Combine into data frame
  prediction_data <- do.call(rbind, prediction_list)
  
  # Join with pool location info
  prediction_data <- prediction_data |>
    left_join(
      pool_info |> select(pool, river, center_rm, n_samples),
      by = c("Pool" = "pool", "River" = "river")
    ) |>
    mutate(
      x_pos = ifelse(River == "IL", 2, 1),
      river_label = ifelse(River == "IL", "Illinois Waterway", "Mississippi River")
    )
  
  return(prediction_data)
}

# Generate predictions
cat("Generating dredging predictions...\n")
dredge_predictions <- create_dredging_prediction_map(
  pool_xgb_results = pool_xgb_results,
  pool_info = pool_info,
  gage_CSAT_joined = gage_CSAT_joined,
  threshold_df = river_thresholds
)

# Check results
if (!is.null(dredge_predictions)) {
  cat(sprintf("\nGenerated %d predictions\n", nrow(dredge_predictions)))
  print(dredge_predictions |> select(Pool, River, Predicted_Rate, Urgency))
} else {
  cat("\nNo predictions generated - see messages above\n")
}
# ============================================================================
# PLOT: Dredging Need by Pool
# ============================================================================

if (!is.null(dredge_predictions) && nrow(dredge_predictions) > 0) {

  p_dredge_map <- ggplot(dredge_predictions, aes(x = x_pos, y = center_rm)) +
    # River lines
    geom_line(aes(group = River), color = "lightblue", linewidth = 10, alpha = 0.3) +
    # Pool points - colored by urgency
    geom_point(aes(size = abs(Predicted_Rate), fill = Urgency), 
               shape = 21, color = "black", alpha = 0.8) +
    # Pool labels
    geom_text(aes(label = Pool), hjust = -0.3, size = 3) +
    # Color scale for urgency
    scale_fill_manual(
      values = c("HIGH" = "#d73027", "MODERATE" = "#fc8d59", 
                 "LOW" = "#fee090", "NONE" = "#91bfdb"),
      name = "Dredging\nUrgency"
    ) +
    scale_size_continuous(range = c(4, 15), name = "Predicted\nRate (ft/yr)") +
    scale_x_continuous(
      breaks = c(1, 2),
      labels = c("Mississippi\nRiver", "Illinois\nWaterway"),
      limits = c(0.5, 2.8)
    ) +
    labs(
      title = "Predicted Dredging Needs by Pool",
      subtitle = paste("Based on most recent survey data | Generated:", Sys.Date()),
      y = "River Mile",
      x = ""
    ) +
    theme_minimal() +
    theme(
      panel.grid.major.x = element_blank(),
      legend.position = "right"
    )

  print(p_dredge_map)
  ggsave("./Output/Maps/Dredging_Predictions_Map.png", width = 12, height = 14)

  # ============================================================================
  # TABLE: Dredging Priority List
  # ============================================================================

  dredge_priority <- dredge_predictions |>
    filter(Dredge_Needed == TRUE) |>
    arrange(desc(Predicted_Rate)) |>
    select(Pool, river_label, Predicted_Rate, Threshold, Urgency, Last_Survey) |>
    mutate(
      Predicted_Rate = round(Predicted_Rate, 2),
      Days_Since_Survey = as.numeric(Sys.Date() - Last_Survey)
    )

  cat("\n=== DREDGING PRIORITY LIST ===\n")
  print(dredge_priority)

  # Save priority list
  write_csv(dredge_priority, "./Output/Maps/Dredging_Priority_List.csv")

} else {
  cat("No dredging predictions available to map\n")
}

```

# Save Results

```{r save-results}
# Save regression results
write_csv(river_results, "./Output/Comparisons/River_Level_Results.csv")

# Save classification results
write_csv(classification_results, "./Output/Comparisons/Classification_Results.csv")

# Save pool results
if (!is.null(pool_xgb_metrics)) {
write_csv(pool_xgb_metrics, "./Output/Pool_Models/Pool_xGBoost_Results.csv")
}

if (!is.null(pool_lstm_metrics)) {
write_csv(pool_lstm_metrics, "./Output/Pool_Models/Pool_LSTM_Results.csv")
}

# Save pool-gage mapping
mapping_df <- data.frame(
Key = names(pool_gage_mapping),
Pool = sapply(pool_gage_mapping, function(x) x$pool),
River = sapply(pool_gage_mapping, function(x) x$river_code),
N_Samples = sapply(pool_gage_mapping, function(x) x$n_samples),
N_Gages = sapply(pool_gage_mapping, function(x) x$n_selected_gages),
Gages = sapply(pool_gage_mapping, function(x) paste(x$selected_gages, collapse = ", "))
)
write_csv(mapping_df, "./Output/Pool_Models/Pool_Gage_Mapping.csv")


```

# Recommendations

```{r recommendations}
generate_recommendations <- function(river_name, regression_data, classification_data) {

best_ml <- regression_data |>
  filter(River == river_name, Model %in% c("xGBoost", "LSTM")) |>
  slice_min(Test_RMSE, n = 1)

best_baseline <- regression_data |>
  filter(River == river_name, Type == "Baseline") |>
  slice_min(Test_RMSE, n = 1)

best_class <- classification_data |>
  filter(Dataset == river_name) |>
  slice_max(F1_Score, n = 1)

improvement <- (best_baseline$Test_RMSE - best_ml$Test_RMSE) / best_baseline$Test_RMSE * 100

cat(sprintf("\n=== %s ===\n", river_name))
cat(sprintf("Best Regression Model: %s (RMSE: %.4f, %.1f%% improvement)\n",
            best_ml$Model, best_ml$Test_RMSE, improvement))
cat(sprintf("Best Classification Model: %s (F1: %.3f)\n",
            best_class$Model, best_class$F1_Score))

if (best_ml$Model == "LSTM") {
  cat("  â Use for: Long-range planning (30-45 days ahead)\n")
} else {
  cat("  â Use for: Real-time predictions, operational deployment\n")
}
}

generate_recommendations("Illinois Waterway", river_results, classification_results)
generate_recommendations("Mississippi River", river_results, classification_results)
generate_recommendations("Combined", river_results, classification_results)
```

# Stop Parallel Processing
```{r cleanup}
# Stop parallel processing cluster
stopCluster(cl)
```
